{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1d31cb-94c2-403d-90ed-b39e1fe4cb6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T19:05:50.169779Z",
     "iopub.status.busy": "2024-08-18T19:05:50.169530Z",
     "iopub.status.idle": "2024-08-18T19:05:56.641509Z",
     "shell.execute_reply": "2024-08-18T19:05:56.640862Z",
     "shell.execute_reply.started": "2024-08-18T19:05:50.169761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (1.7.6)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba) (1.26.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.11.2)\n",
      "Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llvmlite, numba, lightgbm\n",
      "Successfully installed lightgbm-4.5.0 llvmlite-0.43.0 numba-0.60.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numba xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe31f64340966dea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T11:42:55.333078Z",
     "start_time": "2024-08-18T11:42:55.326837Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:05:56.642988Z",
     "iopub.status.busy": "2024-08-18T19:05:56.642800Z",
     "iopub.status.idle": "2024-08-18T19:06:01.209923Z",
     "shell.execute_reply": "2024-08-18T19:06:01.209455Z",
     "shell.execute_reply.started": "2024-08-18T19:05:56.642977Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 19:05:58.134997: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 19:05:58.135137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 19:05:58.216023: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 19:05:58.406500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 19:05:59.805720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0c94c1196e69d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T11:43:25.384192Z",
     "start_time": "2024-08-18T11:43:25.375324Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.210905Z",
     "iopub.status.busy": "2024-08-18T19:06:01.210554Z",
     "iopub.status.idle": "2024-08-18T19:06:01.276268Z",
     "shell.execute_reply": "2024-08-18T19:06:01.275783Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.210889Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Conv1D, MaxPooling1D, Flatten, Activation, SpatialDropout1D, \\\n",
    "    LayerNormalization, Add, Input, GlobalAveragePooling1D\n",
    "import tensorflow.keras.backend as kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62a00f3-d841-4bb4-8d36-d3e5b69f4786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.277864Z",
     "iopub.status.busy": "2024-08-18T19:06:01.277482Z",
     "iopub.status.idle": "2024-08-18T19:06:01.490864Z",
     "shell.execute_reply": "2024-08-18T19:06:01.490332Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.277845Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8aa32a3635907f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T11:46:16.186473Z",
     "start_time": "2024-08-18T11:46:15.962972Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.491732Z",
     "iopub.status.busy": "2024-08-18T19:06:01.491566Z",
     "iopub.status.idle": "2024-08-18T19:06:01.588441Z",
     "shell.execute_reply": "2024-08-18T19:06:01.587876Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.491716Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/Germany_20140101_20231231.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda684d3-cbc6-462f-a015-c6f8a254fb02",
   "metadata": {},
   "source": [
    "### Logging helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a24358-bdbd-4b16-a258-6f54afab61a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.591591Z",
     "iopub.status.busy": "2024-08-18T19:06:01.591381Z",
     "iopub.status.idle": "2024-08-18T19:06:01.596162Z",
     "shell.execute_reply": "2024-08-18T19:06:01.595749Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.591574Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def log(metrics):\n",
    "    \"\"\"\n",
    "    Log the evaluation metrics to a file.\n",
    "\n",
    "    Parameters:\n",
    "    - metrics: Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    # Create the directory structure if it doesn't exist\n",
    "    model_name = metrics['model_name']\n",
    "    window_size = metrics['window_size']\n",
    "\n",
    "    # Define the output path\n",
    "    output_dir = 'results'\n",
    "    output_path = os.path.join('.', output_dir, model_name, \"metrics.csv\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Check if the file already exists\n",
    "    file_exists = os.path.isfile(output_path)\n",
    "\n",
    "    # Write the metrics to the file (append mode)\n",
    "    with open(output_path, 'a') as f:\n",
    "        # Write the header only if the file does not already exist\n",
    "        if not file_exists:\n",
    "            f.write(f\"model_name,window_size,rmse,mae,smape,r2,forecast_bias,training_time\\n\")\n",
    "        f.write(f\"{model_name},{window_size},{metrics['rmse']},{metrics['mae']},{metrics['smape']},{metrics['r2']},{metrics['forecast_bias']},{metrics['training_time']}\\n\")\n",
    "\n",
    "    print(f\"Metrics have been logged to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62448df6aecc168",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.597041Z",
     "iopub.status.busy": "2024-08-18T19:06:01.596915Z",
     "iopub.status.idle": "2024-08-18T19:06:01.602532Z",
     "shell.execute_reply": "2024-08-18T19:06:01.602154Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.597026Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    # Ensure the DataFrame is sorted by date\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # After some EDA we decided to drop these columns\n",
    "    cols_to_drop = ['stations', 'description', 'conditions', 'icon', 'severerisk']\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    # null values in 'sealevelpressure' column are filled with the mean value\n",
    "    df['sealevelpressure'] = df['sealevelpressure'].fillna(df['sealevelpressure'].mean())\n",
    "\n",
    "    # null values in 'visibility' column are filled with the mean value\n",
    "    df['visibility'] = df['visibility'].fillna(df['visibility'].mean())\n",
    "\n",
    "    # null values in 'windgust' column are filled with the 'windspeed' values\n",
    "    df['windgust'] = df['windgust'].fillna(df['windspeed'])\n",
    "\n",
    "    # null values in 'preciptype' column are filled with the 'none'\n",
    "    df['preciptype'] = df['preciptype'].fillna('none')\n",
    "\n",
    "    # 'preciptype' is a categorical feature, so we'll one-hot encode it\n",
    "    df = pd.get_dummies(df, columns=['preciptype'], drop_first=True)\n",
    "\n",
    "    # 'name' is a categorical feature, so we'll one-hot encode it\n",
    "    df = pd.get_dummies(df, columns=['name'], drop_first=True)\n",
    "\n",
    "    # Convert 'datetime' column to datetime if it's not already\n",
    "    if 'datetime' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['datetime']):\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Set 'datetime' as index if it's not already\n",
    "    if 'datetime' in df.columns:\n",
    "        df = df.set_index('datetime')\n",
    "\n",
    "    # Handle 'sunrise' and 'sunset' columns\n",
    "    if 'sunrise' in df.columns and 'sunset' in df.columns:\n",
    "        # Convert to datetime\n",
    "        df['sunrise'] = pd.to_datetime(df['sunrise'])\n",
    "        df['sunset'] = pd.to_datetime(df['sunset'])\n",
    "\n",
    "        # Extract time features\n",
    "        df['sunrise_hour'] = df['sunrise'].dt.hour + df['sunrise'].dt.minute / 60\n",
    "        df['sunset_hour'] = df['sunset'].dt.hour + df['sunset'].dt.minute / 60\n",
    "\n",
    "        # Calculate day length in hours\n",
    "        df['day_length'] = (df['sunset'] - df['sunrise']).dt.total_seconds() / 3600\n",
    "\n",
    "        # Drop original 'sunrise' and 'sunset' columns\n",
    "        df = df.drop(['sunrise', 'sunset'], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "782d44ad0de617fa",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.603218Z",
     "iopub.status.busy": "2024-08-18T19:06:01.603060Z",
     "iopub.status.idle": "2024-08-18T19:06:01.611472Z",
     "shell.execute_reply": "2024-08-18T19:06:01.611053Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.603216Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def split_time_series_data(df, target_column, val_size=0.15, test_size=0.15, window_size=1):\n",
    "    \"\"\"\n",
    "    Split a time series DataFrame into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the time series data\n",
    "    - target_column: string, name of the column to be predicted\n",
    "    - val_size: float, proportion of data to use for validation (default 0.15)\n",
    "    - test_size: float, proportion of data to use for testing (default 0.15)\n",
    "    - window_size: int, size of the sliding window for feature creation (default 1)\n",
    "\n",
    "    Returns:\n",
    "    - x_train, y_train: Training data and labels as DataFrames\n",
    "    - x_val, y_val: Validation data and labels as DataFrames\n",
    "    - x_test, y_test: Test data and labels as DataFrames\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess the DataFrame\n",
    "    df = preprocess_df(df)\n",
    "\n",
    "    # Calculate sizes\n",
    "    train_size = 1 - val_size - test_size\n",
    "    total_size = len(df)\n",
    "    train_end = int(total_size * train_size)\n",
    "    val_end = int(total_size * (train_size + val_size))\n",
    "\n",
    "    # Split the data\n",
    "    train_data = df.iloc[:train_end]\n",
    "    val_data = df.iloc[train_end:val_end]\n",
    "    test_data = df.iloc[val_end:]\n",
    "\n",
    "    # Function to create features and labels\n",
    "    def create_features(data):\n",
    "        features = []\n",
    "        labels = []\n",
    "        for i in range(len(data) - window_size):\n",
    "            features.append(data.iloc[i:i + window_size].drop(columns=[target_column]))\n",
    "            labels.append(data.iloc[i + window_size][target_column])\n",
    "        return pd.concat(features, keys=range(len(features))), pd.Series(labels, name=target_column)\n",
    "\n",
    "    # Create features and labels for each set\n",
    "    x_train, y_train = create_features(train_data)\n",
    "    x_val, y_val = create_features(val_data)\n",
    "    x_test, y_test = create_features(test_data)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "def prepare_for_rnn(df, target_column, val_size=0.15, test_size=0.15, window_size=1):\n",
    "    # Preprocess the DataFrame\n",
    "    df = preprocess_df(df)\n",
    "\n",
    "    # Calculate sizes\n",
    "    train_size = 1 - val_size - test_size\n",
    "    total_size = len(df)\n",
    "    train_end = int(total_size * train_size)\n",
    "    val_end = int(total_size * (train_size + val_size))\n",
    "\n",
    "    # Split the data\n",
    "    train_data = df.iloc[:train_end]\n",
    "    val_data = df.iloc[train_end:val_end]\n",
    "    test_data = df.iloc[val_end:]\n",
    "\n",
    "    # process the data\n",
    "    def process_data(data):\n",
    "        data = data[target_column].values.reshape(-1, 1)\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "        for i in range(window_size, len(data)):\n",
    "            x_.append(data[i - window_size:i, 0])\n",
    "            y_.append(data[i, 0])\n",
    "        return np.array(x_), np.array(y_)\n",
    "\n",
    "    # for training data (scaling and fittransform, the others will be transformed only)\n",
    "    scaper = StandardScaler()\n",
    "    x_train, y_train = process_data(train_data)\n",
    "    x_train = scaper.fit_transform(x_train)\n",
    "\n",
    "    # for validation data\n",
    "    x_val, y_val = process_data(val_data)\n",
    "    x_val = scaper.transform(x_val)\n",
    "\n",
    "    # for test data\n",
    "    x_test, y_test = process_data(test_data)\n",
    "    x_test = scaper.transform(x_test)\n",
    "\n",
    "    # reshape the input data\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4fd53d1-4f8b-4856-a60b-dd1e3bc01d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.612034Z",
     "iopub.status.busy": "2024-08-18T19:06:01.611941Z",
     "iopub.status.idle": "2024-08-18T19:06:01.615561Z",
     "shell.execute_reply": "2024-08-18T19:06:01.615239Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.612023Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_gb_models(df, target, window_size):\n",
    "    x, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        x.append(df.drop(columns=[target]).iloc[i: i+ window_size])\n",
    "        y.append(df.iloc[i + window_size][target])\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    n_samples, window, n_features = x.shape\n",
    "    x = x.reshape((n_samples, window * n_features))\n",
    "    x_train, y_train, x_test, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d404bedb9a5f4",
   "metadata": {},
   "source": [
    "### Data Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4a1371b629fd281",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.617098Z",
     "iopub.status.busy": "2024-08-18T19:06:01.616940Z",
     "iopub.status.idle": "2024-08-18T19:06:01.621274Z",
     "shell.execute_reply": "2024-08-18T19:06:01.620888Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.617098Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_model(\n",
    "        model_name, model_func,\n",
    "        x_train, y_train,\n",
    "        x_val, y_val,\n",
    "        x_test, y_test,\n",
    "        window_size=7):\n",
    "    \"\"\"\n",
    "    Prepare the model and data for training and evaluation. completely manual\n",
    "\n",
    "    Parameters:\n",
    "    - model_name: Name of the model\n",
    "    - model_func: Function to create the model\n",
    "    - x_train, y_train: Training data\n",
    "    - x_val, y_val: Validation data\n",
    "    - x_test, y_test: Testing data\n",
    "    - window_size: Size of the sliding window used\n",
    "\n",
    "    Returns:\n",
    "    - model: The model\n",
    "    - x_train, y_train: Training data and labels\n",
    "    - x_val, y_val: Validation data and labels\n",
    "    - x_test, y_test: Testing data and labels\n",
    "    \"\"\"\n",
    "    if model_name == 'rnn':\n",
    "        # build the model and rturn the data as ism since they were already processed in prepare_for_rnn\n",
    "        model = model_func((window_size, x_train.shape[2]))\n",
    "        print(\"Data and model prepared for RNN\")\n",
    "        return model, x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "    feature_names = x_train.columns.tolist()\n",
    "    model = None  # Placeholder override by the model_func\n",
    "\n",
    "    input_shape = (window_size, len(feature_names))\n",
    "    print(f\"Input shape for {model_name}: {input_shape}\")\n",
    "\n",
    "    # Convert DataFrames to numpy arrays and reshape for RNN models\n",
    "    x_train = x_train.values.reshape(-1, window_size, len(feature_names)).astype(np.float32)\n",
    "    x_val = x_val.values.reshape(-1, window_size, len(feature_names)).astype(np.float32)\n",
    "    x_test = x_test.values.reshape(-1, window_size, len(feature_names)).astype(np.float32)\n",
    "\n",
    "    model = model_func(input_shape)\n",
    "    print(f\"Data prepared for {model_name} model\")\n",
    "    return model, x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a91528f715d1",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf29f3a0a2d7246",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.621917Z",
     "iopub.status.busy": "2024-08-18T19:06:01.621760Z",
     "iopub.status.idle": "2024-08-18T19:06:01.627780Z",
     "shell.execute_reply": "2024-08-18T19:06:01.627290Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.621909Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(\n",
    "        model,\n",
    "        model_name,\n",
    "        x_train, y_train,\n",
    "        x_val, y_val,\n",
    "        x_test, y_test,\n",
    "        window_size,\n",
    "        is_deep_learning=False,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        hyperparams=None):\n",
    "    \"\"\"\n",
    "    Train the model, optionally perform hyperparameter tuning, and evaluate it.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The machine learning model to be trained\n",
    "    - model_name: Name of the model\n",
    "    - X_train, y_train: Training data\n",
    "    - X_val, y_val: Validation data\n",
    "    - X_test, y_test: Testing data\n",
    "    - window_size: Size of the sliding window used\n",
    "    - is_deep_learning: Boolean indicating if it's a deep learning model\n",
    "    - epochs, batch_size: Parameters for deep learning models\n",
    "    - hyperparams: Dictionary of hyperparameters for traditional ML model tuning\n",
    "\n",
    "    Returns:\n",
    "    - model: The trained model\n",
    "    - metrics: Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    if is_deep_learning:\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "        model_checkpoint = ModelCheckpoint(f\"experiment_models/{model_name}_best_model.keras\", save_best_only=True)\n",
    "        history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                            epochs=epochs, batch_size=batch_size,\n",
    "                            callbacks=[early_stopping, model_checkpoint])\n",
    "    elif hyperparams is not None:\n",
    "\n",
    "\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        grid_search = GridSearchCV(model, hyperparams, cv=tscv, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(x_train, y_train)\n",
    "        model = grid_search.best_estimator_\n",
    "\n",
    "    else:\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Ensure y_pred is 1D\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    smape = 100 * np.mean(2 * np.abs(y_pred - y_test) / (np.abs(y_pred) + np.abs(y_test)))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    forecast_bias = np.mean(y_pred - y_test)\n",
    "\n",
    "    # Compile metrics dictionary\n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'window_size': window_size,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'smape': smape,\n",
    "        'r2': r2,\n",
    "        'forecast_bias': forecast_bias,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a172844776322",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb743a026912121",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.628342Z",
     "iopub.status.busy": "2024-08-18T19:06:01.628199Z",
     "iopub.status.idle": "2024-08-18T19:06:01.635729Z",
     "shell.execute_reply": "2024-08-18T19:06:01.635304Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.628338Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ------------------ RNN Model ------------------\n",
    "def create_rnn_model(input_shape, output_units=1):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        SimpleRNN(64, return_sequences=True),\n",
    "        SimpleRNN(32, return_sequences=True),\n",
    "        SimpleRNN(16),\n",
    "        Dense(output_units)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "# ------------------ LSTM Model ------------------\n",
    "def create_lstm_model(input_shape, output_units=1):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        LSTM(32),\n",
    "        Dense(output_units)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "# ------------------ CNN Model ------------------\n",
    "def create_cnn_model(input_shape, output_units=1):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=input_shape, padding='same'),\n",
    "        MaxPooling1D(pool_size=2, padding='same'),\n",
    "        Conv1D(filters=32, kernel_size=2, activation='relu', padding='same'),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(output_units)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "# ------------------ LightGBM Model ------------------\n",
    "def create_lightgbm_model():\n",
    "    return lgb.LGBMRegressor()\n",
    "\n",
    "\n",
    "# ------------------ XGBoost Model ------------------\n",
    "def create_xgboost_model():\n",
    "    return xgb.XGBRegressor()\n",
    "\n",
    "\n",
    "# ------------------ TCM Model ------------------\n",
    "def causal_padding(x):\n",
    "    return kb.temporal_padding(x, (1, 0))\n",
    "\n",
    "\n",
    "def residual_block(x, dilation_rate, nb_filters, kernel_size, dropout_rate=0.1):\n",
    "    prev_x = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "               dilation_rate=dilation_rate, padding='causal')(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SpatialDropout1D(dropout_rate)(x)\n",
    "    x = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "               dilation_rate=dilation_rate, padding='causal')(x)\n",
    "    x = Add()([prev_x, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_tcn_model(input_shape, output_units=1, nb_filters=64, kernel_size=2,\n",
    "                     nb_stacks=1, dilations=[1, 2, 4, 8], dropout_rate=0.2):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(nb_filters, kernel_size, padding='causal', name='initial_conv')(input_layer)\n",
    "\n",
    "    for _ in range(nb_stacks):\n",
    "        for dilation_rate in dilations:\n",
    "            x = residual_block(x, dilation_rate, nb_filters,\n",
    "                               kernel_size, dropout_rate)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(output_units)(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[x])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e0d5f769582b51",
   "metadata": {},
   "source": [
    "### Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742695f971a621ff",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.636593Z",
     "iopub.status.busy": "2024-08-18T19:06:01.636486Z",
     "iopub.status.idle": "2024-08-18T19:06:01.641963Z",
     "shell.execute_reply": "2024-08-18T19:06:01.641581Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.636581Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def do_job(df, target_column, models, results, window_sizes=None):\n",
    "    \n",
    "    if window_sizes is None: window_sizes = [7]\n",
    "    val_size = 0.15\n",
    "    test_size = 0.15\n",
    "    \n",
    "    for model_name, model_func in models.items():\n",
    "        for window_size in window_sizes:\n",
    "            \n",
    "            # check if the model is already trained\n",
    "            trainingdone = False\n",
    "            if len(results[model_name]) > 0:\n",
    "                for key, item in results[model_name].items():\n",
    "                    if f\"{model_name}_{window_size}\" in key:\n",
    "                        print(f\"{model_name} with window size of {window_size} is already trained.\")\n",
    "                        trainingdone = True\n",
    "            if trainingdone:\n",
    "                continue\n",
    "            \n",
    "            print(f\"Training and evaluating {model_name}... with window size of {window_size}\")\n",
    "            \n",
    "            try:\n",
    "                x_train: None\n",
    "                y_train: None\n",
    "                x_val: None\n",
    "                y_val: None\n",
    "                x_test: None\n",
    "                y_test: None\n",
    "                deep_learning = True\n",
    "                epochs = 20\n",
    "                \n",
    "                if model_name == \"rnn\":\n",
    "                    x_train, y_train, x_val, y_val, x_test, y_test = prepare_for_rnn(\n",
    "                        df, target_column, val_size, test_size, window_size\n",
    "                    )\n",
    "                else:\n",
    "                    x_train, y_train, x_val, y_val, x_test, y_test = split_time_series_data(\n",
    "                        df, target_column, val_size, test_size, window_size\n",
    "                    )\n",
    "                \n",
    "                model, x_train, y_train, x_val, y_val, x_test, y_test = prepare_for_model(\n",
    "                    model_name, model_func, \n",
    "                    x_train, y_train, \n",
    "                    x_val, y_val, \n",
    "                    x_test, y_test,\n",
    "                    window_size\n",
    "                )\n",
    "                if model_name != \"rnn\":\n",
    "                    y_train = y_train.values\n",
    "                    y_val = y_val.values\n",
    "                    y_test = y_test.values\n",
    "                    epochs = 100\n",
    "                    \n",
    "                trained_model, metrics = train_and_evaluate_model(\n",
    "                    model, model_name, x_train, y_train, x_val, y_val, x_test, y_test, \n",
    "                    window_size=window_size, is_deep_learning=deep_learning, epochs=epochs\n",
    "                )\n",
    "                \n",
    "                log(metrics)\n",
    "                \n",
    "                results[model_name][f\"{model_name}_{window_size}\"] = metrics\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while training {model_name}: {str(e)}\")\n",
    "                results[model_name][\"metrics\"][f\"{model_name}_{window_size}\"] = \"error\" + str(e)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "333bf4fc4210e189",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.642713Z",
     "iopub.status.busy": "2024-08-18T19:06:01.642566Z",
     "iopub.status.idle": "2024-08-18T19:06:01.645240Z",
     "shell.execute_reply": "2024-08-18T19:06:01.644812Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.642690Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"cnn\": create_cnn_model,\n",
    "    \"lstm\": create_lstm_model,\n",
    "    \"tcn\": create_tcn_model,\n",
    "    \"rnn\": create_rnn_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "416b606aa44ac012",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.646004Z",
     "iopub.status.busy": "2024-08-18T19:06:01.645844Z",
     "iopub.status.idle": "2024-08-18T19:06:01.648506Z",
     "shell.execute_reply": "2024-08-18T19:06:01.648041Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.645972Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"cnn\": { },\n",
    "    \"lstm\": { },\n",
    "    \"tcn\": { },\n",
    "    \"rnn\": { }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28100fea-35ab-48d1-9ce3-14d361523dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.649252Z",
     "iopub.status.busy": "2024-08-18T19:06:01.649064Z",
     "iopub.status.idle": "2024-08-18T19:06:01.651899Z",
     "shell.execute_reply": "2024-08-18T19:06:01.651395Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.649252Z"
    }
   },
   "outputs": [],
   "source": [
    "windows_sizes = [7, 14, 30, 60, 180, 365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d824d9ce4fa30",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T19:06:01.652502Z",
     "iopub.status.busy": "2024-08-18T19:06:01.652343Z",
     "iopub.status.idle": "2024-08-18T21:09:49.113309Z",
     "shell.execute_reply": "2024-08-18T21:09:49.112910Z",
     "shell.execute_reply.started": "2024-08-18T19:06:01.652502Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating cnn... with window size of 7\n",
      "Input shape for cnn: (7, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 19:06:09.334714: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:09.637246: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:09.637416: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:09.639018: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:09.639168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:09.639255: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:11.253950: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:11.254128: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:11.254231: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-18 19:06:11.254315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14223 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:00:05.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared for cnn model\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 19:06:14.816214: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-18 19:06:17.620177: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f168b783510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-18 19:06:17.620189: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2024-08-18 19:06:17.638123: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724007977.752681     127 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 9s 4ms/step - loss: 21.2786 - val_loss: 9.2797\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 7.4111 - val_loss: 9.0902\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 6.1649 - val_loss: 5.1519\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5.5795 - val_loss: 5.7701\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5.6096 - val_loss: 4.5134\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5.4505 - val_loss: 5.1950\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5.1866 - val_loss: 4.1690\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.8805 - val_loss: 4.0412\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.8635 - val_loss: 4.7083\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.6236 - val_loss: 3.8360\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.4095 - val_loss: 4.9892\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.4417 - val_loss: 4.0494\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.3106 - val_loss: 3.7959\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.4875 - val_loss: 4.4899\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.3805 - val_loss: 4.2255\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.3038 - val_loss: 3.8428\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2026 - val_loss: 4.3766\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2113 - val_loss: 6.8600\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2266 - val_loss: 4.4944\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.1781 - val_loss: 3.7109\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2130 - val_loss: 4.1159\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.1840 - val_loss: 4.1432\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.0601 - val_loss: 4.0590\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2026 - val_loss: 3.8879\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9663 - val_loss: 3.8906\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.0873 - val_loss: 3.6471\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.0493 - val_loss: 3.5047\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.1534 - val_loss: 3.7664\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.0193 - val_loss: 4.9299\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9069 - val_loss: 3.6760\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.0230 - val_loss: 3.6888\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.0361 - val_loss: 3.7592\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9179 - val_loss: 3.5362\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8756 - val_loss: 3.8444\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9579 - val_loss: 3.4446\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9389 - val_loss: 4.4226\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8963 - val_loss: 3.4644\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.7851 - val_loss: 3.5788\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.7890 - val_loss: 3.4101\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8463 - val_loss: 3.5781\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8506 - val_loss: 3.5147\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8205 - val_loss: 3.6676\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.7726 - val_loss: 3.4663\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8639 - val_loss: 3.8162\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8303 - val_loss: 3.7149\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8207 - val_loss: 3.5771\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.7170 - val_loss: 3.4609\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.7041 - val_loss: 3.4599\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.6570 - val_loss: 3.4259\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "Metrics have been logged to: ./results/cnn/metrics.csv\n",
      "Training and evaluating cnn... with window size of 14\n",
      "Input shape for cnn: (14, 34)\n",
      "Data prepared for cnn model\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 2s 4ms/step - loss: 29.3072 - val_loss: 15.6846\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 8.3337 - val_loss: 7.4877\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5.7154 - val_loss: 4.4005\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5.2198 - val_loss: 9.1961\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5.2363 - val_loss: 6.1382\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.9565 - val_loss: 4.2626\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.7386 - val_loss: 4.5729\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.8086 - val_loss: 4.1650\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.8167 - val_loss: 3.7895\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.5885 - val_loss: 7.1186\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.5771 - val_loss: 7.7948\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.5182 - val_loss: 3.7569\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.5374 - val_loss: 4.5335\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2857 - val_loss: 4.1735\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2614 - val_loss: 5.3913\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.1906 - val_loss: 4.5394\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2882 - val_loss: 3.5608\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2333 - val_loss: 4.8082\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.4522 - val_loss: 4.2030\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.0396 - val_loss: 3.6371\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.2984 - val_loss: 3.6504\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9772 - val_loss: 3.9153\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.1493 - val_loss: 3.9659\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9951 - val_loss: 3.6015\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9598 - val_loss: 3.5932\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.1019 - val_loss: 3.4354\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8600 - val_loss: 3.6360\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8849 - val_loss: 4.5172\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 4.0475 - val_loss: 4.3294\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9022 - val_loss: 3.8192\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8976 - val_loss: 4.7717\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9041 - val_loss: 3.4527\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.8638 - val_loss: 4.0112\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9171 - val_loss: 3.5401\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.9666 - val_loss: 3.4854\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3.7701 - val_loss: 4.0605\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "Metrics have been logged to: ./results/cnn/metrics.csv\n",
      "Training and evaluating cnn... with window size of 30\n",
      "Input shape for cnn: (30, 34)\n",
      "Data prepared for cnn model\n",
      "Epoch 1/100\n",
      "319/319 [==============================] - 2s 4ms/step - loss: 65.9882 - val_loss: 10.8742\n",
      "Epoch 2/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 11.5215 - val_loss: 9.4556\n",
      "Epoch 3/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 9.1227 - val_loss: 6.8228\n",
      "Epoch 4/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 7.7434 - val_loss: 7.5229\n",
      "Epoch 5/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 6.2629 - val_loss: 8.2305\n",
      "Epoch 6/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 5.7517 - val_loss: 5.0542\n",
      "Epoch 7/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 5.6437 - val_loss: 5.8336\n",
      "Epoch 8/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 5.4280 - val_loss: 5.0959\n",
      "Epoch 9/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 5.2624 - val_loss: 9.5053\n",
      "Epoch 10/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.9307 - val_loss: 5.2593\n",
      "Epoch 11/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 5.0816 - val_loss: 3.9523\n",
      "Epoch 12/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 5.0238 - val_loss: 4.3632\n",
      "Epoch 13/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 5.1283 - val_loss: 4.0821\n",
      "Epoch 14/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.7121 - val_loss: 3.8785\n",
      "Epoch 15/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.7137 - val_loss: 5.1489\n",
      "Epoch 16/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.8333 - val_loss: 5.7656\n",
      "Epoch 17/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.3976 - val_loss: 3.8520\n",
      "Epoch 18/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.4061 - val_loss: 4.1232\n",
      "Epoch 19/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.3506 - val_loss: 4.0021\n",
      "Epoch 20/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.4603 - val_loss: 3.9328\n",
      "Epoch 21/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.1197 - val_loss: 3.6075\n",
      "Epoch 22/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.0834 - val_loss: 3.6500\n",
      "Epoch 23/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.0890 - val_loss: 3.7209\n",
      "Epoch 24/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.0308 - val_loss: 4.4193\n",
      "Epoch 25/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.1379 - val_loss: 3.5540\n",
      "Epoch 26/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.9777 - val_loss: 4.0262\n",
      "Epoch 27/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.9887 - val_loss: 3.6217\n",
      "Epoch 28/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.0507 - val_loss: 3.7163\n",
      "Epoch 29/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.9477 - val_loss: 3.8845\n",
      "Epoch 30/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.1216 - val_loss: 4.2767\n",
      "Epoch 31/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 4.0228 - val_loss: 3.5291\n",
      "Epoch 32/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.9077 - val_loss: 3.8852\n",
      "Epoch 33/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.9426 - val_loss: 3.5110\n",
      "Epoch 34/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.8236 - val_loss: 3.5729\n",
      "Epoch 35/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.8954 - val_loss: 4.2452\n",
      "Epoch 36/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.8555 - val_loss: 3.4009\n",
      "Epoch 37/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7960 - val_loss: 3.8892\n",
      "Epoch 38/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.8719 - val_loss: 4.0011\n",
      "Epoch 39/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7965 - val_loss: 3.8050\n",
      "Epoch 40/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7995 - val_loss: 3.4310\n",
      "Epoch 41/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7256 - val_loss: 3.3828\n",
      "Epoch 42/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7725 - val_loss: 3.4793\n",
      "Epoch 43/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7676 - val_loss: 3.3664\n",
      "Epoch 44/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7383 - val_loss: 3.3461\n",
      "Epoch 45/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7491 - val_loss: 3.7064\n",
      "Epoch 46/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7057 - val_loss: 3.4723\n",
      "Epoch 47/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.6197 - val_loss: 3.4959\n",
      "Epoch 48/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.7062 - val_loss: 3.5779\n",
      "Epoch 49/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.6843 - val_loss: 3.9144\n",
      "Epoch 50/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.6559 - val_loss: 3.5178\n",
      "Epoch 51/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.6191 - val_loss: 3.6691\n",
      "Epoch 52/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.5736 - val_loss: 3.6214\n",
      "Epoch 53/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.5844 - val_loss: 3.4562\n",
      "Epoch 54/100\n",
      "319/319 [==============================] - 1s 3ms/step - loss: 3.5679 - val_loss: 3.3604\n",
      "68/68 [==============================] - 0s 2ms/step\n",
      "Metrics have been logged to: ./results/cnn/metrics.csv\n",
      "Training and evaluating cnn... with window size of 60\n",
      "Input shape for cnn: (60, 34)\n",
      "Data prepared for cnn model\n",
      "Epoch 1/100\n",
      "318/318 [==============================] - 2s 5ms/step - loss: 32.1762 - val_loss: 15.6255\n",
      "Epoch 2/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 14.3913 - val_loss: 10.5644\n",
      "Epoch 3/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 9.8391 - val_loss: 12.2352\n",
      "Epoch 4/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 6.9573 - val_loss: 4.9955\n",
      "Epoch 5/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 6.2600 - val_loss: 5.4992\n",
      "Epoch 6/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 6.3966 - val_loss: 12.9275\n",
      "Epoch 7/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 5.6273 - val_loss: 4.3533\n",
      "Epoch 8/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 5.6267 - val_loss: 4.3762\n",
      "Epoch 9/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 5.1874 - val_loss: 4.1116\n",
      "Epoch 10/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 5.4212 - val_loss: 4.7023\n",
      "Epoch 11/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.9458 - val_loss: 4.2616\n",
      "Epoch 12/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.9598 - val_loss: 4.3194\n",
      "Epoch 13/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.7206 - val_loss: 3.9712\n",
      "Epoch 14/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.6838 - val_loss: 3.8115\n",
      "Epoch 15/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.6866 - val_loss: 5.1997\n",
      "Epoch 16/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.4395 - val_loss: 3.6257\n",
      "Epoch 17/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.4047 - val_loss: 3.6445\n",
      "Epoch 18/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.4361 - val_loss: 3.6529\n",
      "Epoch 19/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.3251 - val_loss: 3.6737\n",
      "Epoch 20/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.3649 - val_loss: 3.8476\n",
      "Epoch 21/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.3955 - val_loss: 3.6256\n",
      "Epoch 22/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.0981 - val_loss: 4.8297\n",
      "Epoch 23/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.2012 - val_loss: 3.8192\n",
      "Epoch 24/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.0430 - val_loss: 4.4640\n",
      "Epoch 25/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.1425 - val_loss: 3.7463\n",
      "Epoch 26/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.0187 - val_loss: 3.5264\n",
      "Epoch 27/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.0111 - val_loss: 5.5924\n",
      "Epoch 28/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.9204 - val_loss: 4.4113\n",
      "Epoch 29/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.0417 - val_loss: 3.6723\n",
      "Epoch 30/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 4.0240 - val_loss: 3.9292\n",
      "Epoch 31/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.8207 - val_loss: 3.3688\n",
      "Epoch 32/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.8850 - val_loss: 3.6718\n",
      "Epoch 33/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.8258 - val_loss: 3.9259\n",
      "Epoch 34/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.9694 - val_loss: 3.6965\n",
      "Epoch 35/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.8991 - val_loss: 3.8193\n",
      "Epoch 36/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.8621 - val_loss: 3.9096\n",
      "Epoch 37/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.9579 - val_loss: 3.7238\n",
      "Epoch 38/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.7656 - val_loss: 3.7726\n",
      "Epoch 39/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.7981 - val_loss: 3.9095\n",
      "Epoch 40/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.7562 - val_loss: 3.3551\n",
      "Epoch 41/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.7571 - val_loss: 3.4853\n",
      "Epoch 42/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.7678 - val_loss: 3.3689\n",
      "Epoch 43/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6906 - val_loss: 3.3938\n",
      "Epoch 44/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.7007 - val_loss: 3.3778\n",
      "Epoch 45/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.7251 - val_loss: 3.4523\n",
      "Epoch 46/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6330 - val_loss: 3.5749\n",
      "Epoch 47/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.7061 - val_loss: 3.3367\n",
      "Epoch 48/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6152 - val_loss: 3.3617\n",
      "Epoch 49/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6232 - val_loss: 3.3647\n",
      "Epoch 50/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6180 - val_loss: 3.7195\n",
      "Epoch 51/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6830 - val_loss: 3.7280\n",
      "Epoch 52/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6189 - val_loss: 3.3026\n",
      "Epoch 53/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6968 - val_loss: 3.3843\n",
      "Epoch 54/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6449 - val_loss: 3.3694\n",
      "Epoch 55/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5508 - val_loss: 3.4383\n",
      "Epoch 56/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5660 - val_loss: 3.3132\n",
      "Epoch 57/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.6285 - val_loss: 3.3635\n",
      "Epoch 58/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5642 - val_loss: 3.5627\n",
      "Epoch 59/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5954 - val_loss: 3.3218\n",
      "Epoch 60/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5355 - val_loss: 3.4246\n",
      "Epoch 61/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5726 - val_loss: 3.2879\n",
      "Epoch 62/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5219 - val_loss: 3.2591\n",
      "Epoch 63/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5439 - val_loss: 3.5317\n",
      "Epoch 64/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5637 - val_loss: 3.4548\n",
      "Epoch 65/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.4827 - val_loss: 3.3782\n",
      "Epoch 66/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5466 - val_loss: 3.3630\n",
      "Epoch 67/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.4996 - val_loss: 3.4237\n",
      "Epoch 68/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.5160 - val_loss: 3.3104\n",
      "Epoch 69/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.4655 - val_loss: 3.5490\n",
      "Epoch 70/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.4753 - val_loss: 3.4568\n",
      "Epoch 71/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.4730 - val_loss: 3.2980\n",
      "Epoch 72/100\n",
      "318/318 [==============================] - 1s 3ms/step - loss: 3.4874 - val_loss: 3.2767\n",
      "67/67 [==============================] - 0s 2ms/step\n",
      "Metrics have been logged to: ./results/cnn/metrics.csv\n",
      "Training and evaluating cnn... with window size of 180\n",
      "Input shape for cnn: (180, 34)\n",
      "Data prepared for cnn model\n",
      "Epoch 1/100\n",
      "314/314 [==============================] - 2s 5ms/step - loss: 70.9110 - val_loss: 18.1308\n",
      "Epoch 2/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 16.0866 - val_loss: 11.5185\n",
      "Epoch 3/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 10.5339 - val_loss: 7.2587\n",
      "Epoch 4/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 7.8817 - val_loss: 6.2623\n",
      "Epoch 5/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 6.4955 - val_loss: 6.1073\n",
      "Epoch 6/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 5.9116 - val_loss: 4.3538\n",
      "Epoch 7/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 5.5885 - val_loss: 4.3880\n",
      "Epoch 8/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 5.4278 - val_loss: 4.7331\n",
      "Epoch 9/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 5.7066 - val_loss: 5.2784\n",
      "Epoch 10/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 5.1895 - val_loss: 4.2046\n",
      "Epoch 11/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 5.1012 - val_loss: 5.7116\n",
      "Epoch 12/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.8968 - val_loss: 4.6422\n",
      "Epoch 13/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.9091 - val_loss: 3.9602\n",
      "Epoch 14/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.8768 - val_loss: 5.2093\n",
      "Epoch 15/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.6652 - val_loss: 3.8083\n",
      "Epoch 16/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.6915 - val_loss: 4.4905\n",
      "Epoch 17/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.6200 - val_loss: 4.8580\n",
      "Epoch 18/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.4085 - val_loss: 3.8828\n",
      "Epoch 19/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.4627 - val_loss: 3.7056\n",
      "Epoch 20/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.4278 - val_loss: 3.7484\n",
      "Epoch 21/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.2441 - val_loss: 4.1376\n",
      "Epoch 22/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.2619 - val_loss: 3.7569\n",
      "Epoch 23/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.2749 - val_loss: 3.8546\n",
      "Epoch 24/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.2654 - val_loss: 3.5834\n",
      "Epoch 25/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.1804 - val_loss: 3.6033\n",
      "Epoch 26/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.0688 - val_loss: 3.5904\n",
      "Epoch 27/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.1587 - val_loss: 3.5477\n",
      "Epoch 28/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.1801 - val_loss: 3.5777\n",
      "Epoch 29/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.1453 - val_loss: 3.7412\n",
      "Epoch 30/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.0718 - val_loss: 3.5087\n",
      "Epoch 31/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.9977 - val_loss: 3.4377\n",
      "Epoch 32/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.9456 - val_loss: 4.0401\n",
      "Epoch 33/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.9415 - val_loss: 3.4872\n",
      "Epoch 34/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.9119 - val_loss: 3.5120\n",
      "Epoch 35/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 4.0223 - val_loss: 3.5465\n",
      "Epoch 36/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.8568 - val_loss: 3.5982\n",
      "Epoch 37/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.8799 - val_loss: 3.5206\n",
      "Epoch 38/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.9495 - val_loss: 3.3704\n",
      "Epoch 39/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.8169 - val_loss: 3.5967\n",
      "Epoch 40/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.8838 - val_loss: 3.5734\n",
      "Epoch 41/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.9012 - val_loss: 4.1610\n",
      "Epoch 42/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.8484 - val_loss: 3.4585\n",
      "Epoch 43/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.8007 - val_loss: 3.4144\n",
      "Epoch 44/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.7762 - val_loss: 3.6436\n",
      "Epoch 45/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.7269 - val_loss: 3.4564\n",
      "Epoch 46/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.7439 - val_loss: 3.3731\n",
      "Epoch 47/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.7087 - val_loss: 3.5617\n",
      "Epoch 48/100\n",
      "314/314 [==============================] - 1s 3ms/step - loss: 3.7057 - val_loss: 3.7835\n",
      "63/63 [==============================] - 0s 3ms/step\n",
      "Metrics have been logged to: ./results/cnn/metrics.csv\n",
      "Training and evaluating cnn... with window size of 365\n",
      "Input shape for cnn: (365, 34)\n",
      "Data prepared for cnn model\n",
      "Epoch 1/100\n",
      "309/309 [==============================] - 3s 6ms/step - loss: 63.4637 - val_loss: 25.3948\n",
      "Epoch 2/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 13.9212 - val_loss: 6.6568\n",
      "Epoch 3/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 6.3770 - val_loss: 7.0052\n",
      "Epoch 4/100\n",
      "309/309 [==============================] - 1s 4ms/step - loss: 5.7078 - val_loss: 4.8931\n",
      "Epoch 5/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 6.1222 - val_loss: 10.8089\n",
      "Epoch 6/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.6992 - val_loss: 4.2921\n",
      "Epoch 7/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.5636 - val_loss: 6.4674\n",
      "Epoch 8/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.4551 - val_loss: 9.0229\n",
      "Epoch 9/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 6.0257 - val_loss: 4.9679\n",
      "Epoch 10/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.3801 - val_loss: 5.2883\n",
      "Epoch 11/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.1940 - val_loss: 9.2038\n",
      "Epoch 12/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.4110 - val_loss: 4.4263\n",
      "Epoch 13/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.2691 - val_loss: 4.0448\n",
      "Epoch 14/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.1814 - val_loss: 4.0407\n",
      "Epoch 15/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.0307 - val_loss: 3.9639\n",
      "Epoch 16/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 5.0166 - val_loss: 7.6142\n",
      "Epoch 17/100\n",
      "309/309 [==============================] - 1s 4ms/step - loss: 4.9062 - val_loss: 4.2000\n",
      "Epoch 18/100\n",
      "309/309 [==============================] - 1s 4ms/step - loss: 4.8100 - val_loss: 3.8630\n",
      "Epoch 19/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.9346 - val_loss: 3.9159\n",
      "Epoch 20/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.5703 - val_loss: 3.8384\n",
      "Epoch 21/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.6774 - val_loss: 3.8116\n",
      "Epoch 22/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.5201 - val_loss: 3.8124\n",
      "Epoch 23/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.5033 - val_loss: 3.9342\n",
      "Epoch 24/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.6025 - val_loss: 4.0543\n",
      "Epoch 25/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.6078 - val_loss: 3.8194\n",
      "Epoch 26/100\n",
      "309/309 [==============================] - 1s 4ms/step - loss: 4.4430 - val_loss: 3.7566\n",
      "Epoch 27/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.6410 - val_loss: 4.6359\n",
      "Epoch 28/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.3784 - val_loss: 3.6785\n",
      "Epoch 29/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.3096 - val_loss: 3.7019\n",
      "Epoch 30/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.4165 - val_loss: 4.8888\n",
      "Epoch 31/100\n",
      "309/309 [==============================] - 1s 4ms/step - loss: 4.2373 - val_loss: 4.1373\n",
      "Epoch 32/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.2757 - val_loss: 3.7174\n",
      "Epoch 33/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.3520 - val_loss: 3.6685\n",
      "Epoch 34/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.2370 - val_loss: 3.5617\n",
      "Epoch 35/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.2722 - val_loss: 4.3104\n",
      "Epoch 36/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.2135 - val_loss: 3.6570\n",
      "Epoch 37/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.0871 - val_loss: 4.2184\n",
      "Epoch 38/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.0974 - val_loss: 5.2075\n",
      "Epoch 39/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.1108 - val_loss: 5.0281\n",
      "Epoch 40/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.1792 - val_loss: 3.5389\n",
      "Epoch 41/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.0743 - val_loss: 3.5290\n",
      "Epoch 42/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.0363 - val_loss: 3.5993\n",
      "Epoch 43/100\n",
      "309/309 [==============================] - 1s 4ms/step - loss: 4.2399 - val_loss: 3.6488\n",
      "Epoch 44/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.0433 - val_loss: 4.0927\n",
      "Epoch 45/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 4.0022 - val_loss: 3.4781\n",
      "Epoch 46/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.9648 - val_loss: 3.7393\n",
      "Epoch 47/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.9906 - val_loss: 3.6008\n",
      "Epoch 48/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.9418 - val_loss: 4.1302\n",
      "Epoch 49/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.9958 - val_loss: 3.6600\n",
      "Epoch 50/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.9150 - val_loss: 4.3471\n",
      "Epoch 51/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.9354 - val_loss: 3.6071\n",
      "Epoch 52/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.9833 - val_loss: 3.5491\n",
      "Epoch 53/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.8294 - val_loss: 3.8478\n",
      "Epoch 54/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.8237 - val_loss: 3.8399\n",
      "Epoch 55/100\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 3.8842 - val_loss: 3.4900\n",
      "58/58 [==============================] - 0s 3ms/step\n",
      "Metrics have been logged to: ./results/cnn/metrics.csv\n",
      "Training and evaluating lstm... with window size of 7\n",
      "Input shape for lstm: (7, 34)\n",
      "Data prepared for lstm model\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 4s 5ms/step - loss: 60.0761 - val_loss: 31.2542\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 18.0570 - val_loss: 12.1495\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 10.8573 - val_loss: 10.1531\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 9.2119 - val_loss: 8.4648\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 8.5500 - val_loss: 8.0786\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 7.8901 - val_loss: 7.7860\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 7.5939 - val_loss: 6.8525\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 7.2760 - val_loss: 6.5890\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.9359 - val_loss: 6.6517\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.8354 - val_loss: 6.4269\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.6909 - val_loss: 6.0300\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.5521 - val_loss: 6.1741\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.4422 - val_loss: 6.1655\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.2875 - val_loss: 6.6078\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.3496 - val_loss: 5.7943\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.1263 - val_loss: 5.5248\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.8106 - val_loss: 5.2859\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.9913 - val_loss: 5.2889\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.9272 - val_loss: 5.6151\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.7527 - val_loss: 5.3449\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.7799 - val_loss: 4.8617\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.6728 - val_loss: 5.0200\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.6326 - val_loss: 4.9064\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.5051 - val_loss: 5.3370\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.4542 - val_loss: 4.7904\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.2669 - val_loss: 4.4504\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.3627 - val_loss: 4.8565\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.3341 - val_loss: 4.9072\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.3214 - val_loss: 4.9788\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.2105 - val_loss: 5.3341\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.2271 - val_loss: 4.3905\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.5632 - val_loss: 4.8262\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.1945 - val_loss: 4.6615\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.1233 - val_loss: 4.8822\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.0014 - val_loss: 4.2071\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.0387 - val_loss: 4.3152\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.0418 - val_loss: 4.3490\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.9155 - val_loss: 4.3341\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.9913 - val_loss: 4.1875\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.8771 - val_loss: 5.2795\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.8979 - val_loss: 4.3958\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.9460 - val_loss: 4.6242\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.9198 - val_loss: 4.3467\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.8384 - val_loss: 4.2662\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 4.7564 - val_loss: 4.1877\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6159 - val_loss: 4.5883\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6222 - val_loss: 3.9863\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.7644 - val_loss: 4.7220\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6670 - val_loss: 3.9595\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.5550 - val_loss: 4.8862\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.5638 - val_loss: 4.6319\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6432 - val_loss: 5.3996\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.7964 - val_loss: 4.6522\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.5131 - val_loss: 4.1225\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.5197 - val_loss: 4.3483\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6587 - val_loss: 4.3045\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6688 - val_loss: 3.9215\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6392 - val_loss: 4.0295\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6632 - val_loss: 4.5708\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.4388 - val_loss: 4.0459\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.5212 - val_loss: 4.4740\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.5439 - val_loss: 4.3908\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.3999 - val_loss: 4.2407\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.4626 - val_loss: 4.1771\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.3791 - val_loss: 4.1474\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.4160 - val_loss: 4.1510\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.3922 - val_loss: 3.9391\n",
      "69/69 [==============================] - 1s 2ms/step\n",
      "Metrics have been logged to: ./results/lstm/metrics.csv\n",
      "Training and evaluating lstm... with window size of 14\n",
      "Input shape for lstm: (14, 34)\n",
      "Data prepared for lstm model\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 4s 6ms/step - loss: 46.7976 - val_loss: 21.9713\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 12.8139 - val_loss: 9.6094\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 1s 5ms/step - loss: 8.3435 - val_loss: 7.1646\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 1s 5ms/step - loss: 6.7651 - val_loss: 6.0452\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 6.0358 - val_loss: 5.6023\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.7293 - val_loss: 5.4220\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.4855 - val_loss: 4.9806\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.4182 - val_loss: 4.9366\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.4950 - val_loss: 5.0083\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 5.3083 - val_loss: 5.1393\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.9954 - val_loss: 4.9087\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.9179 - val_loss: 4.8061\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.9430 - val_loss: 4.6658\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.7755 - val_loss: 4.7159\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 4.7438 - val_loss: 4.1688\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 1s 5ms/step - loss: 4.6989 - val_loss: 5.2780\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6385 - val_loss: 4.3679\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6448 - val_loss: 4.4894\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6532 - val_loss: 4.3447\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.7314 - val_loss: 4.2400\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6077 - val_loss: 4.2298\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.5474 - val_loss: 4.2621\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.6525 - val_loss: 4.1914\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.5578 - val_loss: 4.4973\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 4.4778 - val_loss: 4.2391\n",
      "69/69 [==============================] - 1s 2ms/step\n",
      "Metrics have been logged to: ./results/lstm/metrics.csv\n",
      "Training and evaluating lstm... with window size of 30\n",
      "Input shape for lstm: (30, 34)\n",
      "Data prepared for lstm model\n",
      "Epoch 1/100\n",
      "319/319 [==============================] - 4s 7ms/step - loss: 47.6977 - val_loss: 20.5348\n",
      "Epoch 2/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 12.5472 - val_loss: 9.4803\n",
      "Epoch 3/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 8.0172 - val_loss: 6.8310\n",
      "Epoch 4/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 6.6971 - val_loss: 5.9722\n",
      "Epoch 5/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 5.9098 - val_loss: 5.4837\n",
      "Epoch 6/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 5.6568 - val_loss: 5.6521\n",
      "Epoch 7/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 5.5889 - val_loss: 5.5873\n",
      "Epoch 8/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 5.3142 - val_loss: 5.5056\n",
      "Epoch 9/100\n",
      "319/319 [==============================] - 2s 6ms/step - loss: 5.1744 - val_loss: 5.0491\n",
      "Epoch 10/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 5.0482 - val_loss: 4.3893\n",
      "Epoch 11/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 5.0016 - val_loss: 4.6479\n",
      "Epoch 12/100\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 4.8209 - val_loss: 4.6086\n",
      "Epoch 13/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 5.0221 - val_loss: 4.4726\n",
      "Epoch 14/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.7296 - val_loss: 4.5661\n",
      "Epoch 15/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.7585 - val_loss: 4.3808\n",
      "Epoch 16/100\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 4.7329 - val_loss: 4.1648\n",
      "Epoch 17/100\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 4.4848 - val_loss: 4.3895\n",
      "Epoch 18/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.6130 - val_loss: 4.0656\n",
      "Epoch 19/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.5507 - val_loss: 4.2496\n",
      "Epoch 20/100\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 4.4905 - val_loss: 4.2043\n",
      "Epoch 21/100\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 4.6473 - val_loss: 4.1453\n",
      "Epoch 22/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.6300 - val_loss: 4.1762\n",
      "Epoch 23/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.5764 - val_loss: 4.4536\n",
      "Epoch 24/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.5186 - val_loss: 4.3296\n",
      "Epoch 25/100\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 4.4975 - val_loss: 4.2388\n",
      "Epoch 26/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.4979 - val_loss: 3.9161\n",
      "Epoch 27/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.4240 - val_loss: 4.2792\n",
      "Epoch 28/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.4736 - val_loss: 4.1330\n",
      "Epoch 29/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.3973 - val_loss: 4.0255\n",
      "Epoch 30/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.4290 - val_loss: 4.2103\n",
      "Epoch 31/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.4016 - val_loss: 4.3396\n",
      "Epoch 32/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.4581 - val_loss: 4.5028\n",
      "Epoch 33/100\n",
      "319/319 [==============================] - 1s 5ms/step - loss: 4.4721 - val_loss: 4.1516\n",
      "Epoch 34/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.3335 - val_loss: 4.0408\n",
      "Epoch 35/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.5527 - val_loss: 4.2869\n",
      "Epoch 36/100\n",
      "319/319 [==============================] - 2s 5ms/step - loss: 4.4361 - val_loss: 4.0660\n",
      "68/68 [==============================] - 1s 2ms/step\n",
      "Metrics have been logged to: ./results/lstm/metrics.csv\n",
      "Training and evaluating lstm... with window size of 60\n",
      "Input shape for lstm: (60, 34)\n",
      "Data prepared for lstm model\n",
      "Epoch 1/100\n",
      "318/318 [==============================] - 4s 7ms/step - loss: 49.5540 - val_loss: 22.5913\n",
      "Epoch 2/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 13.4033 - val_loss: 10.6862\n",
      "Epoch 3/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 8.3770 - val_loss: 7.6704\n",
      "Epoch 4/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 6.9341 - val_loss: 7.1617\n",
      "Epoch 5/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 6.2143 - val_loss: 6.1205\n",
      "Epoch 6/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 5.7130 - val_loss: 5.2529\n",
      "Epoch 7/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 5.4560 - val_loss: 5.1094\n",
      "Epoch 8/100\n",
      "318/318 [==============================] - 2s 7ms/step - loss: 5.3228 - val_loss: 4.9455\n",
      "Epoch 9/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 5.1445 - val_loss: 4.8849\n",
      "Epoch 10/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 5.0023 - val_loss: 5.0239\n",
      "Epoch 11/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 5.0288 - val_loss: 4.7261\n",
      "Epoch 12/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.9330 - val_loss: 4.4473\n",
      "Epoch 13/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.7896 - val_loss: 4.6533\n",
      "Epoch 14/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.7152 - val_loss: 4.5119\n",
      "Epoch 15/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.6745 - val_loss: 4.6126\n",
      "Epoch 16/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.8209 - val_loss: 4.2737\n",
      "Epoch 17/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.7221 - val_loss: 4.5435\n",
      "Epoch 18/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.7076 - val_loss: 4.2605\n",
      "Epoch 19/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.6691 - val_loss: 4.7991\n",
      "Epoch 20/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.7623 - val_loss: 4.6527\n",
      "Epoch 21/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.7330 - val_loss: 4.4759\n",
      "Epoch 22/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.6460 - val_loss: 4.4287\n",
      "Epoch 23/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.5646 - val_loss: 4.3239\n",
      "Epoch 24/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.4968 - val_loss: 4.3666\n",
      "Epoch 25/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.4993 - val_loss: 4.4614\n",
      "Epoch 26/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.6340 - val_loss: 4.1839\n",
      "Epoch 27/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.6121 - val_loss: 4.1901\n",
      "Epoch 28/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.5085 - val_loss: 4.0341\n",
      "Epoch 29/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.4827 - val_loss: 4.5006\n",
      "Epoch 30/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.4505 - val_loss: 4.0373\n",
      "Epoch 31/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.4976 - val_loss: 4.3444\n",
      "Epoch 32/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.4461 - val_loss: 4.5467\n",
      "Epoch 33/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.4265 - val_loss: 4.2209\n",
      "Epoch 34/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.4308 - val_loss: 4.4528\n",
      "Epoch 35/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.3609 - val_loss: 4.4720\n",
      "Epoch 36/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2708 - val_loss: 3.8429\n",
      "Epoch 37/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2617 - val_loss: 3.9584\n",
      "Epoch 38/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2535 - val_loss: 4.0101\n",
      "Epoch 39/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2931 - val_loss: 4.0205\n",
      "Epoch 40/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.3031 - val_loss: 3.9037\n",
      "Epoch 41/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.3980 - val_loss: 3.9206\n",
      "Epoch 42/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2946 - val_loss: 4.1827\n",
      "Epoch 43/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2793 - val_loss: 3.8028\n",
      "Epoch 44/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.1826 - val_loss: 4.3231\n",
      "Epoch 45/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2942 - val_loss: 4.0026\n",
      "Epoch 46/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2573 - val_loss: 3.8532\n",
      "Epoch 47/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.1729 - val_loss: 3.9256\n",
      "Epoch 48/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2322 - val_loss: 4.0014\n",
      "Epoch 49/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2694 - val_loss: 4.2282\n",
      "Epoch 50/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.1757 - val_loss: 4.0308\n",
      "Epoch 51/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.2026 - val_loss: 3.9849\n",
      "Epoch 52/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.1749 - val_loss: 4.4213\n",
      "Epoch 53/100\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 4.3792 - val_loss: 4.0386\n",
      "67/67 [==============================] - 1s 2ms/step\n",
      "Metrics have been logged to: ./results/lstm/metrics.csv\n",
      "Training and evaluating lstm... with window size of 180\n",
      "Input shape for lstm: (180, 34)\n",
      "Data prepared for lstm model\n",
      "Epoch 1/100\n",
      "314/314 [==============================] - 6s 12ms/step - loss: 57.5588 - val_loss: 27.5504\n",
      "Epoch 2/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 15.9151 - val_loss: 11.4938\n",
      "Epoch 3/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 9.3174 - val_loss: 8.2409\n",
      "Epoch 4/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 7.6562 - val_loss: 6.8579\n",
      "Epoch 5/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 6.8893 - val_loss: 6.3793\n",
      "Epoch 6/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 6.3360 - val_loss: 6.1602\n",
      "Epoch 7/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 6.0285 - val_loss: 5.5017\n",
      "Epoch 8/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.8198 - val_loss: 5.2184\n",
      "Epoch 9/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.7370 - val_loss: 5.2756\n",
      "Epoch 10/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.6724 - val_loss: 5.0843\n",
      "Epoch 11/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.6037 - val_loss: 5.0540\n",
      "Epoch 12/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.4862 - val_loss: 5.0607\n",
      "Epoch 13/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.4704 - val_loss: 5.1555\n",
      "Epoch 14/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.4913 - val_loss: 5.2835\n",
      "Epoch 15/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.4655 - val_loss: 4.8280\n",
      "Epoch 16/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.4611 - val_loss: 4.6865\n",
      "Epoch 17/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5.2853 - val_loss: 4.5907\n",
      "Epoch 18/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.2636 - val_loss: 4.7075\n",
      "Epoch 19/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.1966 - val_loss: 5.4086\n",
      "Epoch 20/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.2536 - val_loss: 4.7480\n",
      "Epoch 21/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.2254 - val_loss: 6.2679\n",
      "Epoch 22/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.1900 - val_loss: 5.1450\n",
      "Epoch 23/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.1084 - val_loss: 5.3297\n",
      "Epoch 24/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.2116 - val_loss: 5.0869\n",
      "Epoch 25/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 5.1188 - val_loss: 4.7689\n",
      "Epoch 26/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 4.9332 - val_loss: 5.0723\n",
      "Epoch 27/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 4.9881 - val_loss: 5.6006\n",
      "63/63 [==============================] - 1s 4ms/step\n",
      "Metrics have been logged to: ./results/lstm/metrics.csv\n",
      "Training and evaluating lstm... with window size of 365\n",
      "Input shape for lstm: (365, 34)\n",
      "Data prepared for lstm model\n",
      "Epoch 1/100\n",
      "309/309 [==============================] - 8s 19ms/step - loss: 48.3286 - val_loss: 20.4726\n",
      "Epoch 2/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 13.8835 - val_loss: 11.4873\n",
      "Epoch 3/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 9.0121 - val_loss: 8.9159\n",
      "Epoch 4/100\n",
      "309/309 [==============================] - 5s 18ms/step - loss: 7.4253 - val_loss: 7.1293\n",
      "Epoch 5/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 6.6396 - val_loss: 6.1688\n",
      "Epoch 6/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 6.0011 - val_loss: 5.5055\n",
      "Epoch 7/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 5.9529 - val_loss: 5.7560\n",
      "Epoch 8/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 5.7661 - val_loss: 5.4985\n",
      "Epoch 9/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 5.7029 - val_loss: 5.0840\n",
      "Epoch 10/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 5.5655 - val_loss: 5.3970\n",
      "Epoch 11/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 5.2972 - val_loss: 4.6996\n",
      "Epoch 12/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 5.4130 - val_loss: 4.8640\n",
      "Epoch 13/100\n",
      "309/309 [==============================] - 5s 18ms/step - loss: 5.2605 - val_loss: 4.6293\n",
      "Epoch 14/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 5.1093 - val_loss: 4.5480\n",
      "Epoch 15/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 4.9954 - val_loss: 4.4257\n",
      "Epoch 16/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 5.0170 - val_loss: 4.8790\n",
      "Epoch 17/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 5.0496 - val_loss: 4.5368\n",
      "Epoch 18/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 5.0329 - val_loss: 4.9771\n",
      "Epoch 19/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 4.9339 - val_loss: 4.3353\n",
      "Epoch 20/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 4.7747 - val_loss: 4.4958\n",
      "Epoch 21/100\n",
      "309/309 [==============================] - 5s 18ms/step - loss: 4.8339 - val_loss: 4.8933\n",
      "Epoch 22/100\n",
      "309/309 [==============================] - 5s 18ms/step - loss: 4.6957 - val_loss: 3.9664\n",
      "Epoch 23/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 4.6682 - val_loss: 4.4637\n",
      "Epoch 24/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 4.5936 - val_loss: 4.8006\n",
      "Epoch 25/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 4.7691 - val_loss: 4.2666\n",
      "Epoch 26/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 4.7276 - val_loss: 4.8015\n",
      "Epoch 27/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 4.5885 - val_loss: 4.5855\n",
      "Epoch 28/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 4.7118 - val_loss: 4.6023\n",
      "Epoch 29/100\n",
      "309/309 [==============================] - 5s 17ms/step - loss: 4.6798 - val_loss: 4.1812\n",
      "Epoch 30/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 4.6112 - val_loss: 4.5881\n",
      "Epoch 31/100\n",
      "309/309 [==============================] - 6s 18ms/step - loss: 4.7121 - val_loss: 4.5660\n",
      "Epoch 32/100\n",
      "309/309 [==============================] - 5s 18ms/step - loss: 4.6285 - val_loss: 4.3639\n",
      "58/58 [==============================] - 1s 7ms/step\n",
      "Metrics have been logged to: ./results/lstm/metrics.csv\n",
      "Training and evaluating tcn... with window size of 7\n",
      "Input shape for tcn: (7, 34)\n",
      "Data prepared for tcn model\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 9s 13ms/step - loss: 581.2905 - val_loss: 15.5403\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 16.1736 - val_loss: 13.7599\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 13.0780 - val_loss: 10.6054\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 12.1569 - val_loss: 9.9819\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 11.7502 - val_loss: 11.3131\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 10.9085 - val_loss: 9.7309\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 10.6356 - val_loss: 8.6537\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 10.2030 - val_loss: 10.3444\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 9.4739 - val_loss: 8.0735\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 9.4394 - val_loss: 7.2154\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 8.8639 - val_loss: 6.7416\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 8.2414 - val_loss: 6.5995\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 8.6148 - val_loss: 9.9521\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 7.7413 - val_loss: 6.2738\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 7.2698 - val_loss: 6.1990\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 7.7429 - val_loss: 6.0581\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 6.7785 - val_loss: 5.3799\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 7.0985 - val_loss: 6.5100\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 6.9027 - val_loss: 5.2060\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 6.8457 - val_loss: 8.5678\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 6.4801 - val_loss: 5.5515\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 6.3785 - val_loss: 6.4851\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 6.3328 - val_loss: 4.9096\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.9825 - val_loss: 4.9052\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.8989 - val_loss: 5.6347\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.9009 - val_loss: 7.9853\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 6.1887 - val_loss: 7.2035\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 6.5730 - val_loss: 6.7685\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.2902 - val_loss: 5.8649\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.9078 - val_loss: 7.2543\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.3046 - val_loss: 4.7568\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.6609 - val_loss: 4.3603\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.1400 - val_loss: 6.3823\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.6207 - val_loss: 6.4758\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.0739 - val_loss: 4.6138\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.3914 - val_loss: 4.4151\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.2365 - val_loss: 6.5472\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.7901 - val_loss: 5.9004\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.1616 - val_loss: 4.2205\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.7452 - val_loss: 9.2026\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.0729 - val_loss: 4.5865\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.8596 - val_loss: 3.7667\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.6768 - val_loss: 4.2648\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.5642 - val_loss: 3.7460\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 3s 11ms/step - loss: 4.7121 - val_loss: 5.1673\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.8029 - val_loss: 5.5057\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.0618 - val_loss: 4.0862\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.0824 - val_loss: 4.1605\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.7495 - val_loss: 4.9990\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.6531 - val_loss: 4.7676\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.6191 - val_loss: 4.3265\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.6568 - val_loss: 5.0164\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.6786 - val_loss: 3.7599\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.3273 - val_loss: 8.2795\n",
      "69/69 [==============================] - 1s 5ms/step\n",
      "Metrics have been logged to: ./results/tcn/metrics.csv\n",
      "Training and evaluating tcn... with window size of 14\n",
      "Input shape for tcn: (14, 34)\n",
      "Data prepared for tcn model\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 9s 14ms/step - loss: 357.3114 - val_loss: 16.7579\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 3s 11ms/step - loss: 16.4758 - val_loss: 12.2349\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 13.8971 - val_loss: 10.9055\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 12.7512 - val_loss: 11.5762\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 11.8637 - val_loss: 10.6104\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 11.3726 - val_loss: 10.9329\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 11.4377 - val_loss: 8.8310\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 10.0364 - val_loss: 8.5879\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 9.6801 - val_loss: 11.1742\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 9.7075 - val_loss: 16.9132\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 8.9423 - val_loss: 7.1527\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 8.0710 - val_loss: 8.6488\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 7.5846 - val_loss: 5.7364\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 7.3960 - val_loss: 6.9138\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 7.6767 - val_loss: 5.5850\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 6.7043 - val_loss: 26.8465\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 7.1033 - val_loss: 6.2676\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 6.0327 - val_loss: 5.0572\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 6.0209 - val_loss: 5.4404\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.6288 - val_loss: 6.1064\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.4033 - val_loss: 5.0105\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.7660 - val_loss: 6.8557\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 6.4592 - val_loss: 4.5615\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.7762 - val_loss: 7.2583\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.5431 - val_loss: 4.2706\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.8057 - val_loss: 4.1355\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.3082 - val_loss: 8.5160\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.1068 - val_loss: 8.1552\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.5444 - val_loss: 4.2550\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.0071 - val_loss: 5.2228\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 5.4634 - val_loss: 4.9654\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.6302 - val_loss: 5.7873\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.7834 - val_loss: 4.0940\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.1005 - val_loss: 5.7405\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.9093 - val_loss: 7.5240\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.9322 - val_loss: 4.5851\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.5676 - val_loss: 7.6923\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 5.1367 - val_loss: 3.9477\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.3092 - val_loss: 3.9128\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 3s 11ms/step - loss: 4.5772 - val_loss: 8.1529\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.3915 - val_loss: 8.0055\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.8466 - val_loss: 4.1918\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.8337 - val_loss: 4.1052\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.5025 - val_loss: 3.7043\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.5957 - val_loss: 3.7500\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.6064 - val_loss: 8.0939\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.7125 - val_loss: 14.0641\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.2220 - val_loss: 6.3620\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.4703 - val_loss: 6.5632\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.3722 - val_loss: 13.5826\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.2086 - val_loss: 4.0624\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.3492 - val_loss: 3.6802\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.3282 - val_loss: 3.6857\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.3791 - val_loss: 3.9758\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.2479 - val_loss: 3.9229\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 4.1870 - val_loss: 7.8848\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.5328 - val_loss: 6.5950\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 4.1305 - val_loss: 7.0466\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 3.7670 - val_loss: 5.6407\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 3s 10ms/step - loss: 3.8836 - val_loss: 3.9491\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 3.6409 - val_loss: 3.8255\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 3.8122 - val_loss: 4.1006\n",
      "69/69 [==============================] - 1s 6ms/step\n",
      "Metrics have been logged to: ./results/tcn/metrics.csv\n",
      "Training and evaluating tcn... with window size of 30\n",
      "Input shape for tcn: (30, 34)\n",
      "Data prepared for tcn model\n",
      "Epoch 1/100\n",
      "319/319 [==============================] - 9s 14ms/step - loss: 166.3146 - val_loss: 15.0279\n",
      "Epoch 2/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 15.5102 - val_loss: 14.2095\n",
      "Epoch 3/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 14.7346 - val_loss: 18.1293\n",
      "Epoch 4/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 13.6579 - val_loss: 18.4252\n",
      "Epoch 5/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 13.3697 - val_loss: 11.9649\n",
      "Epoch 6/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 13.3379 - val_loss: 12.0178\n",
      "Epoch 7/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 13.2638 - val_loss: 11.1314\n",
      "Epoch 8/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 12.7773 - val_loss: 10.8145\n",
      "Epoch 9/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 12.4681 - val_loss: 14.0489\n",
      "Epoch 10/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 12.9604 - val_loss: 11.9575\n",
      "Epoch 11/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 11.4490 - val_loss: 11.8651\n",
      "Epoch 12/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 11.9747 - val_loss: 14.9150\n",
      "Epoch 13/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 11.4946 - val_loss: 10.1840\n",
      "Epoch 14/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 9.6930 - val_loss: 8.2373\n",
      "Epoch 15/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 10.6052 - val_loss: 9.1127\n",
      "Epoch 16/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 9.1995 - val_loss: 13.4633\n",
      "Epoch 17/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 8.8518 - val_loss: 12.7073\n",
      "Epoch 18/100\n",
      "319/319 [==============================] - 3s 11ms/step - loss: 9.1627 - val_loss: 7.0217\n",
      "Epoch 19/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 8.8547 - val_loss: 6.4410\n",
      "Epoch 20/100\n",
      "319/319 [==============================] - 3s 11ms/step - loss: 7.5788 - val_loss: 6.0435\n",
      "Epoch 21/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 7.8941 - val_loss: 9.7402\n",
      "Epoch 22/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 7.2718 - val_loss: 5.6037\n",
      "Epoch 23/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 7.2908 - val_loss: 6.4708\n",
      "Epoch 24/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 7.5073 - val_loss: 5.3783\n",
      "Epoch 25/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 7.0218 - val_loss: 7.4848\n",
      "Epoch 26/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.5864 - val_loss: 5.1206\n",
      "Epoch 27/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.6976 - val_loss: 5.1454\n",
      "Epoch 28/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 6.2601 - val_loss: 5.5476\n",
      "Epoch 29/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.8266 - val_loss: 5.4902\n",
      "Epoch 30/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.1148 - val_loss: 4.6555\n",
      "Epoch 31/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.7868 - val_loss: 4.6724\n",
      "Epoch 32/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.2458 - val_loss: 8.0252\n",
      "Epoch 33/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.0831 - val_loss: 5.1035\n",
      "Epoch 34/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.3206 - val_loss: 6.0886\n",
      "Epoch 35/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.2056 - val_loss: 17.2524\n",
      "Epoch 36/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.8820 - val_loss: 4.5137\n",
      "Epoch 37/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.8526 - val_loss: 4.1860\n",
      "Epoch 38/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.5907 - val_loss: 9.3413\n",
      "Epoch 39/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.5682 - val_loss: 5.1431\n",
      "Epoch 40/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.7425 - val_loss: 4.5710\n",
      "Epoch 41/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 5.1346 - val_loss: 8.4843\n",
      "Epoch 42/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.4553 - val_loss: 5.1059\n",
      "Epoch 43/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 5.1805 - val_loss: 9.4224\n",
      "Epoch 44/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 6.2649 - val_loss: 4.8641\n",
      "Epoch 45/100\n",
      "319/319 [==============================] - 3s 9ms/step - loss: 5.1674 - val_loss: 8.3705\n",
      "Epoch 46/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.1007 - val_loss: 8.6638\n",
      "Epoch 47/100\n",
      "319/319 [==============================] - 3s 10ms/step - loss: 5.2945 - val_loss: 10.0404\n",
      "68/68 [==============================] - 1s 6ms/step\n",
      "Metrics have been logged to: ./results/tcn/metrics.csv\n",
      "Training and evaluating tcn... with window size of 60\n",
      "Input shape for tcn: (60, 34)\n",
      "Data prepared for tcn model\n",
      "Epoch 1/100\n",
      "318/318 [==============================] - 9s 14ms/step - loss: 78.2594 - val_loss: 17.3966\n",
      "Epoch 2/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 17.1728 - val_loss: 13.9319\n",
      "Epoch 3/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 15.3287 - val_loss: 16.2628\n",
      "Epoch 4/100\n",
      "318/318 [==============================] - 3s 11ms/step - loss: 15.2086 - val_loss: 13.7602\n",
      "Epoch 5/100\n",
      "318/318 [==============================] - 3s 11ms/step - loss: 14.1847 - val_loss: 12.5938\n",
      "Epoch 6/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 14.7938 - val_loss: 12.0784\n",
      "Epoch 7/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 14.5802 - val_loss: 12.0284\n",
      "Epoch 8/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 13.8894 - val_loss: 11.5416\n",
      "Epoch 9/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 14.1400 - val_loss: 17.2134\n",
      "Epoch 10/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 14.3392 - val_loss: 11.4842\n",
      "Epoch 11/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 14.0101 - val_loss: 21.3182\n",
      "Epoch 12/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 13.4181 - val_loss: 13.3702\n",
      "Epoch 13/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 13.3880 - val_loss: 15.2425\n",
      "Epoch 14/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 12.8599 - val_loss: 11.2298\n",
      "Epoch 15/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 13.4807 - val_loss: 11.9143\n",
      "Epoch 16/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 12.4258 - val_loss: 11.8122\n",
      "Epoch 17/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 13.4789 - val_loss: 13.4579\n",
      "Epoch 18/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 11.6883 - val_loss: 16.4219\n",
      "Epoch 19/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 11.6454 - val_loss: 10.1556\n",
      "Epoch 20/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 12.7418 - val_loss: 13.8923\n",
      "Epoch 21/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 11.3515 - val_loss: 10.0394\n",
      "Epoch 22/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 11.0307 - val_loss: 9.6884\n",
      "Epoch 23/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 10.1153 - val_loss: 9.4031\n",
      "Epoch 24/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 10.1166 - val_loss: 8.4699\n",
      "Epoch 25/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 10.2462 - val_loss: 10.1429\n",
      "Epoch 26/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 10.8507 - val_loss: 8.9205\n",
      "Epoch 27/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 9.3586 - val_loss: 12.9305\n",
      "Epoch 28/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 8.6601 - val_loss: 7.9175\n",
      "Epoch 29/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 9.4789 - val_loss: 8.7540\n",
      "Epoch 30/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 8.9167 - val_loss: 7.3978\n",
      "Epoch 31/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 8.1161 - val_loss: 7.4784\n",
      "Epoch 32/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 8.0214 - val_loss: 9.2874\n",
      "Epoch 33/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 7.8613 - val_loss: 7.3412\n",
      "Epoch 34/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 7.7504 - val_loss: 6.9146\n",
      "Epoch 35/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 8.0506 - val_loss: 6.6392\n",
      "Epoch 36/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 7.2066 - val_loss: 7.1199\n",
      "Epoch 37/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 7.9967 - val_loss: 6.3457\n",
      "Epoch 38/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 6.5736 - val_loss: 8.4758\n",
      "Epoch 39/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 7.1934 - val_loss: 7.6961\n",
      "Epoch 40/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 6.6380 - val_loss: 6.5007\n",
      "Epoch 41/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 6.9390 - val_loss: 5.9556\n",
      "Epoch 42/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 6.6467 - val_loss: 10.2321\n",
      "Epoch 43/100\n",
      "318/318 [==============================] - 3s 11ms/step - loss: 7.2606 - val_loss: 6.4865\n",
      "Epoch 44/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 6.4612 - val_loss: 9.9469\n",
      "Epoch 45/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 7.0158 - val_loss: 6.8492\n",
      "Epoch 46/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 6.1010 - val_loss: 7.9657\n",
      "Epoch 47/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 6.6584 - val_loss: 7.6340\n",
      "Epoch 48/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.9414 - val_loss: 5.8086\n",
      "Epoch 49/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 6.0002 - val_loss: 7.4982\n",
      "Epoch 50/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.7683 - val_loss: 8.7480\n",
      "Epoch 51/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 5.9935 - val_loss: 7.8483\n",
      "Epoch 52/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.9437 - val_loss: 5.9658\n",
      "Epoch 53/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.8021 - val_loss: 11.5600\n",
      "Epoch 54/100\n",
      "318/318 [==============================] - 3s 11ms/step - loss: 5.6009 - val_loss: 6.5518\n",
      "Epoch 55/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.7709 - val_loss: 7.5513\n",
      "Epoch 56/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 6.0687 - val_loss: 5.8871\n",
      "Epoch 57/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.4446 - val_loss: 5.7027\n",
      "Epoch 58/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.4942 - val_loss: 5.8620\n",
      "Epoch 59/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 5.3839 - val_loss: 5.7769\n",
      "Epoch 60/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.4199 - val_loss: 9.3663\n",
      "Epoch 61/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.3520 - val_loss: 5.7475\n",
      "Epoch 62/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.2321 - val_loss: 5.8355\n",
      "Epoch 63/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 5.4666 - val_loss: 10.8522\n",
      "Epoch 64/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.2517 - val_loss: 10.3552\n",
      "Epoch 65/100\n",
      "318/318 [==============================] - 3s 9ms/step - loss: 5.3829 - val_loss: 6.9512\n",
      "Epoch 66/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.4066 - val_loss: 7.8776\n",
      "Epoch 67/100\n",
      "318/318 [==============================] - 3s 10ms/step - loss: 5.5670 - val_loss: 5.9496\n",
      "67/67 [==============================] - 1s 7ms/step\n",
      "Metrics have been logged to: ./results/tcn/metrics.csv\n",
      "Training and evaluating tcn... with window size of 180\n",
      "Input shape for tcn: (180, 34)\n",
      "Data prepared for tcn model\n",
      "Epoch 1/100\n",
      "314/314 [==============================] - 9s 14ms/step - loss: 694.2035 - val_loss: 94.0255\n",
      "Epoch 2/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 36.6015 - val_loss: 43.3848\n",
      "Epoch 3/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 20.5929 - val_loss: 26.1010\n",
      "Epoch 4/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 16.6675 - val_loss: 23.8267\n",
      "Epoch 5/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 15.3494 - val_loss: 18.5536\n",
      "Epoch 6/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 14.8799 - val_loss: 31.0933\n",
      "Epoch 7/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 15.1397 - val_loss: 20.9467\n",
      "Epoch 8/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 14.7144 - val_loss: 15.6889\n",
      "Epoch 9/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 15.0181 - val_loss: 16.6607\n",
      "Epoch 10/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 14.5391 - val_loss: 13.6561\n",
      "Epoch 11/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 15.1976 - val_loss: 17.1405\n",
      "Epoch 12/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 15.2446 - val_loss: 21.0385\n",
      "Epoch 13/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 15.1081 - val_loss: 13.3845\n",
      "Epoch 14/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 14.6734 - val_loss: 14.9021\n",
      "Epoch 15/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 14.8947 - val_loss: 15.3433\n",
      "Epoch 16/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 15.2940 - val_loss: 13.8390\n",
      "Epoch 17/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 14.5708 - val_loss: 18.0864\n",
      "Epoch 18/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 14.8276 - val_loss: 19.8638\n",
      "Epoch 19/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 14.2921 - val_loss: 14.7517\n",
      "Epoch 20/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 14.2711 - val_loss: 14.7036\n",
      "Epoch 21/100\n",
      "314/314 [==============================] - 3s 10ms/step - loss: 14.3916 - val_loss: 18.7464\n",
      "Epoch 22/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 14.7367 - val_loss: 31.2315\n",
      "Epoch 23/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 14.5916 - val_loss: 22.4301\n",
      "63/63 [==============================] - 1s 8ms/step\n",
      "Metrics have been logged to: ./results/tcn/metrics.csv\n",
      "Training and evaluating tcn... with window size of 365\n",
      "Input shape for tcn: (365, 34)\n",
      "Data prepared for tcn model\n",
      "Epoch 1/100\n",
      "309/309 [==============================] - 10s 18ms/step - loss: 86.1816 - val_loss: 46.2572\n",
      "Epoch 2/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 31.1653 - val_loss: 19.0594\n",
      "Epoch 3/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 19.4784 - val_loss: 15.9989\n",
      "Epoch 4/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 19.0180 - val_loss: 16.7843\n",
      "Epoch 5/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 18.5820 - val_loss: 16.2034\n",
      "Epoch 6/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 19.2604 - val_loss: 16.4500\n",
      "Epoch 7/100\n",
      "309/309 [==============================] - 4s 13ms/step - loss: 17.8380 - val_loss: 36.4836\n",
      "Epoch 8/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 17.4671 - val_loss: 14.8025\n",
      "Epoch 9/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 18.0190 - val_loss: 16.8996\n",
      "Epoch 10/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 17.9432 - val_loss: 14.9199\n",
      "Epoch 11/100\n",
      "309/309 [==============================] - 4s 13ms/step - loss: 17.1252 - val_loss: 14.8465\n",
      "Epoch 12/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 17.5443 - val_loss: 18.8925\n",
      "Epoch 13/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.7897 - val_loss: 21.9080\n",
      "Epoch 14/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 18.6979 - val_loss: 15.3776\n",
      "Epoch 15/100\n",
      "309/309 [==============================] - 5s 15ms/step - loss: 17.0475 - val_loss: 27.0998\n",
      "Epoch 16/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 16.2559 - val_loss: 13.9163\n",
      "Epoch 17/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.9764 - val_loss: 14.3282\n",
      "Epoch 18/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 16.2735 - val_loss: 32.0149\n",
      "Epoch 19/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 16.4850 - val_loss: 15.2509\n",
      "Epoch 20/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.3596 - val_loss: 14.7731\n",
      "Epoch 21/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.9997 - val_loss: 13.2574\n",
      "Epoch 22/100\n",
      "309/309 [==============================] - 4s 13ms/step - loss: 15.5400 - val_loss: 14.4587\n",
      "Epoch 23/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.1752 - val_loss: 13.7009\n",
      "Epoch 24/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 16.4453 - val_loss: 31.0991\n",
      "Epoch 25/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.9182 - val_loss: 25.9261\n",
      "Epoch 26/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.7175 - val_loss: 19.3212\n",
      "Epoch 27/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.4544 - val_loss: 13.4054\n",
      "Epoch 28/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 15.5249 - val_loss: 23.7175\n",
      "Epoch 29/100\n",
      "309/309 [==============================] - 4s 14ms/step - loss: 14.3989 - val_loss: 13.9949\n",
      "Epoch 30/100\n",
      "309/309 [==============================] - 4s 13ms/step - loss: 14.7883 - val_loss: 15.6082\n",
      "Epoch 31/100\n",
      "309/309 [==============================] - 4s 15ms/step - loss: 15.5053 - val_loss: 21.1558\n",
      "58/58 [==============================] - 1s 9ms/step\n",
      "Metrics have been logged to: ./results/tcn/metrics.csv\n",
      "Training and evaluating rnn... with window size of 7\n",
      "Data and model prepared for RNN\n",
      "Epoch 1/20\n",
      "320/320 [==============================] - 7s 14ms/step - loss: 62.2831 - val_loss: 43.1408\n",
      "Epoch 2/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 24.9013 - val_loss: 20.6529\n",
      "Epoch 3/20\n",
      "320/320 [==============================] - 4s 14ms/step - loss: 13.0529 - val_loss: 11.8862\n",
      "Epoch 4/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 8.4855 - val_loss: 8.1648\n",
      "Epoch 5/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 6.6380 - val_loss: 6.3051\n",
      "Epoch 6/20\n",
      "320/320 [==============================] - 4s 14ms/step - loss: 5.7668 - val_loss: 5.4199\n",
      "Epoch 7/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 5.3041 - val_loss: 5.0752\n",
      "Epoch 8/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 5.0644 - val_loss: 4.9989\n",
      "Epoch 9/20\n",
      "320/320 [==============================] - 4s 14ms/step - loss: 5.5644 - val_loss: 4.9343\n",
      "Epoch 10/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.8720 - val_loss: 5.1769\n",
      "Epoch 11/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.7924 - val_loss: 4.2477\n",
      "Epoch 12/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.6749 - val_loss: 4.2563\n",
      "Epoch 13/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.6374 - val_loss: 4.1830\n",
      "Epoch 14/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.5946 - val_loss: 4.2995\n",
      "Epoch 15/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.5795 - val_loss: 4.0200\n",
      "Epoch 16/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.5251 - val_loss: 4.0763\n",
      "Epoch 17/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.5632 - val_loss: 3.9566\n",
      "Epoch 18/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.5617 - val_loss: 4.0849\n",
      "Epoch 19/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.5779 - val_loss: 4.2264\n",
      "Epoch 20/20\n",
      "320/320 [==============================] - 4s 13ms/step - loss: 4.5529 - val_loss: 4.0802\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "Metrics have been logged to: ./results/rnn/metrics.csv\n",
      "Training and evaluating rnn... with window size of 14\n",
      "Data and model prepared for RNN\n",
      "Epoch 1/20\n",
      "320/320 [==============================] - 10s 23ms/step - loss: 61.7748 - val_loss: 43.8061\n",
      "Epoch 2/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 25.2117 - val_loss: 22.0440\n",
      "Epoch 3/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 13.3876 - val_loss: 12.4242\n",
      "Epoch 4/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 8.6583 - val_loss: 8.3835\n",
      "Epoch 5/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 6.7260 - val_loss: 6.7579\n",
      "Epoch 6/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 6.0935 - val_loss: 5.8407\n",
      "Epoch 7/20\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 5.3106 - val_loss: 5.0952\n",
      "Epoch 8/20\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 5.0236 - val_loss: 4.8075\n",
      "Epoch 9/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 4.9067 - val_loss: 4.5458\n",
      "Epoch 10/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 4.7851 - val_loss: 4.2961\n",
      "Epoch 11/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 4.6993 - val_loss: 4.2365\n",
      "Epoch 12/20\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 4.7041 - val_loss: 4.1790\n",
      "Epoch 13/20\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 4.5996 - val_loss: 4.2253\n",
      "Epoch 14/20\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 4.6064 - val_loss: 4.0858\n",
      "Epoch 15/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 4.5626 - val_loss: 4.0430\n",
      "Epoch 16/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 4.5565 - val_loss: 4.0482\n",
      "Epoch 17/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 4.5785 - val_loss: 4.0241\n",
      "Epoch 18/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 4.5081 - val_loss: 4.1469\n",
      "Epoch 19/20\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 4.5247 - val_loss: 4.1904\n",
      "Epoch 20/20\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 4.4801 - val_loss: 3.9066\n",
      "69/69 [==============================] - 0s 4ms/step\n",
      "Metrics have been logged to: ./results/rnn/metrics.csv\n",
      "Training and evaluating rnn... with window size of 30\n",
      "Data and model prepared for RNN\n",
      "Epoch 1/20\n",
      "319/319 [==============================] - 15s 43ms/step - loss: 54.6611 - val_loss: 35.9690\n",
      "Epoch 2/20\n",
      "319/319 [==============================] - 14s 43ms/step - loss: 23.4160 - val_loss: 34.2883\n",
      "Epoch 3/20\n",
      "319/319 [==============================] - 14s 43ms/step - loss: 12.0162 - val_loss: 10.5475\n",
      "Epoch 4/20\n",
      "319/319 [==============================] - 13s 42ms/step - loss: 7.8515 - val_loss: 7.4890\n",
      "Epoch 5/20\n",
      "319/319 [==============================] - 13s 42ms/step - loss: 6.2599 - val_loss: 6.2047\n",
      "Epoch 6/20\n",
      "319/319 [==============================] - 13s 42ms/step - loss: 5.5812 - val_loss: 5.2972\n",
      "Epoch 7/20\n",
      "319/319 [==============================] - 14s 42ms/step - loss: 5.2298 - val_loss: 4.8100\n",
      "Epoch 8/20\n",
      "319/319 [==============================] - 13s 42ms/step - loss: 4.9641 - val_loss: 4.4971\n",
      "Epoch 9/20\n",
      "319/319 [==============================] - 14s 43ms/step - loss: 4.8831 - val_loss: 4.2698\n",
      "Epoch 10/20\n",
      "319/319 [==============================] - 14s 42ms/step - loss: 4.8240 - val_loss: 4.1892\n",
      "Epoch 11/20\n",
      "319/319 [==============================] - 14s 45ms/step - loss: 4.7658 - val_loss: 4.4488\n",
      "Epoch 12/20\n",
      "319/319 [==============================] - 14s 43ms/step - loss: 4.6734 - val_loss: 4.5464\n",
      "Epoch 13/20\n",
      "319/319 [==============================] - 14s 42ms/step - loss: 4.6396 - val_loss: 4.2671\n",
      "Epoch 14/20\n",
      "319/319 [==============================] - 13s 42ms/step - loss: 4.6173 - val_loss: 4.1904\n",
      "Epoch 15/20\n",
      "319/319 [==============================] - 14s 44ms/step - loss: 4.6394 - val_loss: 4.1196\n",
      "Epoch 16/20\n",
      "319/319 [==============================] - 14s 43ms/step - loss: 4.5741 - val_loss: 4.1103\n",
      "Epoch 17/20\n",
      "319/319 [==============================] - 14s 43ms/step - loss: 4.6067 - val_loss: 4.1362\n",
      "Epoch 18/20\n",
      "319/319 [==============================] - 13s 42ms/step - loss: 4.5629 - val_loss: 3.9819\n",
      "Epoch 19/20\n",
      "319/319 [==============================] - 13s 41ms/step - loss: 4.6250 - val_loss: 4.1679\n",
      "Epoch 20/20\n",
      "319/319 [==============================] - 13s 41ms/step - loss: 4.5529 - val_loss: 4.0451\n",
      "68/68 [==============================] - 1s 6ms/step\n",
      "Metrics have been logged to: ./results/rnn/metrics.csv\n",
      "Training and evaluating rnn... with window size of 60\n",
      "Data and model prepared for RNN\n",
      "Epoch 1/20\n",
      "318/318 [==============================] - 27s 80ms/step - loss: 85.6369 - val_loss: 65.1580\n",
      "Epoch 2/20\n",
      "318/318 [==============================] - 26s 80ms/step - loss: 37.7633 - val_loss: 29.7989\n",
      "Epoch 3/20\n",
      "318/318 [==============================] - 26s 81ms/step - loss: 17.6890 - val_loss: 16.0556\n",
      "Epoch 4/20\n",
      "318/318 [==============================] - 26s 82ms/step - loss: 10.5821 - val_loss: 10.5049\n",
      "Epoch 5/20\n",
      "318/318 [==============================] - 26s 80ms/step - loss: 7.6366 - val_loss: 7.9907\n",
      "Epoch 6/20\n",
      "318/318 [==============================] - 26s 82ms/step - loss: 6.3098 - val_loss: 6.2173\n",
      "Epoch 7/20\n",
      "318/318 [==============================] - 26s 83ms/step - loss: 5.5701 - val_loss: 5.6107\n",
      "Epoch 8/20\n",
      "318/318 [==============================] - 25s 80ms/step - loss: 5.1886 - val_loss: 4.9000\n",
      "Epoch 9/20\n",
      "318/318 [==============================] - 26s 82ms/step - loss: 4.9573 - val_loss: 4.8134\n",
      "Epoch 10/20\n",
      "318/318 [==============================] - 26s 81ms/step - loss: 4.8390 - val_loss: 4.4815\n",
      "Epoch 11/20\n",
      "318/318 [==============================] - 26s 82ms/step - loss: 6.6282 - val_loss: 4.4755\n",
      "Epoch 12/20\n",
      "318/318 [==============================] - 26s 83ms/step - loss: 4.6911 - val_loss: 4.2360\n",
      "Epoch 13/20\n",
      "318/318 [==============================] - 25s 80ms/step - loss: 4.5725 - val_loss: 4.2367\n",
      "Epoch 14/20\n",
      "318/318 [==============================] - 26s 82ms/step - loss: 4.5122 - val_loss: 4.1049\n",
      "Epoch 15/20\n",
      "318/318 [==============================] - 26s 81ms/step - loss: 4.4768 - val_loss: 4.0664\n",
      "Epoch 16/20\n",
      "318/318 [==============================] - 26s 81ms/step - loss: 4.4975 - val_loss: 4.0007\n",
      "Epoch 17/20\n",
      "318/318 [==============================] - 26s 81ms/step - loss: 4.4366 - val_loss: 4.1582\n",
      "Epoch 18/20\n",
      "318/318 [==============================] - 27s 84ms/step - loss: 4.4376 - val_loss: 4.0762\n",
      "Epoch 19/20\n",
      "318/318 [==============================] - 26s 83ms/step - loss: 4.4094 - val_loss: 4.0466\n",
      "Epoch 20/20\n",
      "318/318 [==============================] - 26s 81ms/step - loss: 4.3864 - val_loss: 4.0293\n",
      "67/67 [==============================] - 1s 11ms/step\n",
      "Metrics have been logged to: ./results/rnn/metrics.csv\n",
      "Training and evaluating rnn... with window size of 180\n",
      "Data and model prepared for RNN\n",
      "Epoch 1/20\n",
      "314/314 [==============================] - 74s 231ms/step - loss: 61.8614 - val_loss: 42.0310\n",
      "Epoch 2/20\n",
      "314/314 [==============================] - 73s 233ms/step - loss: 23.8830 - val_loss: 20.0547\n",
      "Epoch 3/20\n",
      "314/314 [==============================] - 72s 230ms/step - loss: 12.5167 - val_loss: 11.6210\n",
      "Epoch 4/20\n",
      "314/314 [==============================] - 72s 230ms/step - loss: 8.2846 - val_loss: 8.0675\n",
      "Epoch 5/20\n",
      "314/314 [==============================] - 72s 229ms/step - loss: 6.4745 - val_loss: 6.5040\n",
      "Epoch 6/20\n",
      "314/314 [==============================] - 72s 228ms/step - loss: 5.6584 - val_loss: 5.6270\n",
      "Epoch 7/20\n",
      "314/314 [==============================] - 72s 231ms/step - loss: 5.2928 - val_loss: 5.0062\n",
      "Epoch 8/20\n",
      "314/314 [==============================] - 73s 231ms/step - loss: 5.0007 - val_loss: 4.8756\n",
      "Epoch 9/20\n",
      "314/314 [==============================] - 72s 230ms/step - loss: 4.8755 - val_loss: 4.4869\n",
      "Epoch 10/20\n",
      "314/314 [==============================] - 72s 231ms/step - loss: 4.7378 - val_loss: 4.4089\n",
      "Epoch 11/20\n",
      "314/314 [==============================] - 72s 228ms/step - loss: 4.8540 - val_loss: 4.5120\n",
      "Epoch 12/20\n",
      "314/314 [==============================] - 73s 232ms/step - loss: 4.6433 - val_loss: 4.1356\n",
      "Epoch 13/20\n",
      "314/314 [==============================] - 72s 231ms/step - loss: 4.5208 - val_loss: 4.0449\n",
      "Epoch 14/20\n",
      "314/314 [==============================] - 72s 230ms/step - loss: 4.5201 - val_loss: 4.1125\n",
      "Epoch 15/20\n",
      "314/314 [==============================] - 72s 230ms/step - loss: 4.5122 - val_loss: 4.0441\n",
      "Epoch 16/20\n",
      "314/314 [==============================] - 73s 232ms/step - loss: 4.4610 - val_loss: 4.0066\n",
      "Epoch 17/20\n",
      "314/314 [==============================] - 72s 231ms/step - loss: 4.4018 - val_loss: 4.1491\n",
      "Epoch 18/20\n",
      "314/314 [==============================] - 73s 232ms/step - loss: 4.4285 - val_loss: 4.0656\n",
      "Epoch 19/20\n",
      "314/314 [==============================] - 72s 230ms/step - loss: 4.5258 - val_loss: 4.0117\n",
      "Epoch 20/20\n",
      "314/314 [==============================] - 71s 228ms/step - loss: 9.7494 - val_loss: 4.6429\n",
      "63/63 [==============================] - 2s 30ms/step\n",
      "Metrics have been logged to: ./results/rnn/metrics.csv\n",
      "Training and evaluating rnn... with window size of 365\n",
      "Data and model prepared for RNN\n",
      "Epoch 1/20\n",
      "309/309 [==============================] - 146s 467ms/step - loss: 75.8031 - val_loss: 54.7971\n",
      "Epoch 2/20\n",
      "309/309 [==============================] - 144s 465ms/step - loss: 32.0600 - val_loss: 26.8044\n",
      "Epoch 3/20\n",
      "309/309 [==============================] - 144s 465ms/step - loss: 16.8185 - val_loss: 15.4852\n",
      "Epoch 4/20\n",
      "309/309 [==============================] - 145s 470ms/step - loss: 10.4297 - val_loss: 10.6956\n",
      "Epoch 5/20\n",
      "309/309 [==============================] - 146s 473ms/step - loss: 7.6385 - val_loss: 7.7456\n",
      "Epoch 6/20\n",
      "309/309 [==============================] - 145s 468ms/step - loss: 6.4152 - val_loss: 6.3094\n",
      "Epoch 7/20\n",
      "309/309 [==============================] - 144s 467ms/step - loss: 6.1523 - val_loss: 5.7461\n",
      "Epoch 8/20\n",
      "309/309 [==============================] - 144s 465ms/step - loss: 5.3218 - val_loss: 4.9205\n",
      "Epoch 9/20\n",
      "309/309 [==============================] - 145s 469ms/step - loss: 5.0182 - val_loss: 4.5964\n",
      "Epoch 10/20\n",
      "309/309 [==============================] - 145s 469ms/step - loss: 4.8326 - val_loss: 4.4021\n",
      "Epoch 11/20\n",
      "309/309 [==============================] - 145s 470ms/step - loss: 4.7680 - val_loss: 4.3358\n",
      "Epoch 12/20\n",
      "309/309 [==============================] - 143s 462ms/step - loss: 4.7051 - val_loss: 4.3674\n",
      "Epoch 13/20\n",
      "309/309 [==============================] - 144s 467ms/step - loss: 4.6307 - val_loss: 4.0845\n",
      "Epoch 14/20\n",
      "309/309 [==============================] - 144s 467ms/step - loss: 4.6252 - val_loss: 4.0906\n",
      "Epoch 15/20\n",
      "309/309 [==============================] - 144s 466ms/step - loss: 4.5837 - val_loss: 4.0404\n",
      "Epoch 16/20\n",
      "309/309 [==============================] - 144s 466ms/step - loss: 4.5583 - val_loss: 4.2509\n",
      "Epoch 17/20\n",
      "309/309 [==============================] - 145s 470ms/step - loss: 4.5008 - val_loss: 4.0567\n",
      "Epoch 18/20\n",
      "309/309 [==============================] - 145s 470ms/step - loss: 4.5164 - val_loss: 4.0087\n",
      "Epoch 19/20\n",
      "309/309 [==============================] - 145s 471ms/step - loss: 4.5146 - val_loss: 4.0245\n",
      "Epoch 20/20\n",
      "309/309 [==============================] - 143s 463ms/step - loss: 4.5034 - val_loss: 4.1284\n",
      "58/58 [==============================] - 4s 59ms/step\n",
      "Metrics have been logged to: ./results/rnn/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "results = do_job(data, \"temp\", models, results, windows_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a0fe10e58773e1f",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-18T21:09:49.114558Z",
     "iopub.status.busy": "2024-08-18T21:09:49.113989Z",
     "iopub.status.idle": "2024-08-18T21:09:49.118856Z",
     "shell.execute_reply": "2024-08-18T21:09:49.118447Z",
     "shell.execute_reply.started": "2024-08-18T21:09:49.114558Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for cnn\n",
      "window_size: 7\n",
      "rmse: 1.8438046530812073\n",
      "mae: 1.4263358697929425\n",
      "smape: 20.67530451959958\n",
      "r2: 0.9373058439973899\n",
      "forecast_bias: 0.48628158737101873\n",
      "training_time: 51.649333000183105\n",
      "___\n",
      "window_size: 14\n",
      "rmse: 1.942795476353371\n",
      "mae: 1.5226419753081157\n",
      "smape: 21.490223530904046\n",
      "r2: 0.9304391709262545\n",
      "forecast_bias: -0.6809481710435\n",
      "training_time: 33.48738694190979\n",
      "___\n",
      "window_size: 30\n",
      "rmse: 1.781208494605541\n",
      "mae: 1.3871125896799894\n",
      "smape: 20.788647242261003\n",
      "r2: 0.9415457091053503\n",
      "forecast_bias: 0.030387294238173053\n",
      "training_time: 49.61276650428772\n",
      "___\n",
      "window_size: 60\n",
      "rmse: 1.7546349849888667\n",
      "mae: 1.3493007248816191\n",
      "smape: 19.818515055854586\n",
      "r2: 0.9418602905740197\n",
      "forecast_bias: -0.05552328635517363\n",
      "training_time: 66.48372149467468\n",
      "___\n",
      "window_size: 180\n",
      "rmse: 1.9885828220726796\n",
      "mae: 1.5563020118365942\n",
      "smape: 21.367518607271446\n",
      "r2: 0.9256233130039209\n",
      "forecast_bias: 0.6680741243138465\n",
      "training_time: 47.68547487258911\n",
      "___\n",
      "window_size: 365\n",
      "rmse: 1.882897563867991\n",
      "mae: 1.4623371909208878\n",
      "smape: 21.416146778644965\n",
      "r2: 0.9312035897959579\n",
      "forecast_bias: 0.3408630990433967\n",
      "training_time: 59.58492112159729\n",
      "___\n",
      "=======\n",
      "Results for lstm\n",
      "window_size: 7\n",
      "rmse: 1.948502868473424\n",
      "mae: 1.5077983007114595\n",
      "smape: 22.029736947259682\n",
      "r2: 0.9299836695178293\n",
      "forecast_bias: 0.03370501163076753\n",
      "training_time: 88.11536002159119\n",
      "___\n",
      "window_size: 14\n",
      "rmse: 2.0809660605235307\n",
      "mae: 1.627083037578808\n",
      "smape: 22.617143405734176\n",
      "r2: 0.9201930751524088\n",
      "forecast_bias: 0.08055099930042954\n",
      "training_time: 37.04864478111267\n",
      "___\n",
      "window_size: 30\n",
      "rmse: 2.002471665233987\n",
      "mae: 1.550708026581622\n",
      "smape: 23.141997236814074\n",
      "r2: 0.92612123270603\n",
      "forecast_bias: -0.21095021728229785\n",
      "training_time: 83.69633483886719\n",
      "___\n",
      "window_size: 60\n",
      "rmse: 2.002387321763183\n",
      "mae: 1.5610304234790533\n",
      "smape: 22.10065443760153\n",
      "r2: 0.92428264022824\n",
      "forecast_bias: -0.033420667835069195\n",
      "training_time: 102.63526821136475\n",
      "___\n",
      "window_size: 180\n",
      "rmse: 2.4202543148817295\n",
      "mae: 1.9334060776926887\n",
      "smape: 25.35934187955161\n",
      "r2: 0.8898279403758347\n",
      "forecast_bias: 1.0078071413854246\n",
      "training_time: 91.795241355896\n",
      "___\n",
      "window_size: 365\n",
      "rmse: 2.078831234629831\n",
      "mae: 1.6267325978332616\n",
      "smape: 24.750427582701143\n",
      "r2: 0.9161407725247124\n",
      "forecast_bias: -0.09754038197979878\n",
      "training_time: 177.9744246006012\n",
      "___\n",
      "=======\n",
      "Results for tcn\n",
      "window_size: 7\n",
      "rmse: 2.8204039854565686\n",
      "mae: 2.3561997277008317\n",
      "smape: 37.32901293904124\n",
      "r2: 0.8533034547000188\n",
      "forecast_bias: -2.134494910496596\n",
      "training_time: 174.5549192428589\n",
      "___\n",
      "window_size: 14\n",
      "rmse: 2.0458535896985217\n",
      "mae: 1.6156948144305618\n",
      "smape: 22.92919886930483\n",
      "r2: 0.9228635436772735\n",
      "forecast_bias: 0.7609252972270066\n",
      "training_time: 198.58393359184265\n",
      "___\n",
      "window_size: 30\n",
      "rmse: 3.2011532150570052\n",
      "mae: 2.7129955870916107\n",
      "smape: 41.99871706144549\n",
      "r2: 0.8112009505896394\n",
      "forecast_bias: -2.512575924739149\n",
      "training_time: 153.0530288219452\n",
      "___\n",
      "window_size: 60\n",
      "rmse: 2.4017498028247277\n",
      "mae: 1.903030105568355\n",
      "smape: 25.683158897684994\n",
      "r2: 0.8910681659776204\n",
      "forecast_bias: -0.3023345775801363\n",
      "training_time: 216.410710811615\n",
      "___\n",
      "window_size: 180\n",
      "rmse: 4.66443137879175\n",
      "mae: 3.744435839667716\n",
      "smape: 57.56819471851371\n",
      "r2: 0.5907893962414936\n",
      "forecast_bias: -2.789587870751421\n",
      "training_time: 81.05532169342041\n",
      "___\n",
      "window_size: 365\n",
      "rmse: 4.895178739090514\n",
      "mae: 4.037386999681712\n",
      "smape: 56.90632790652883\n",
      "r2: 0.5350036989647917\n",
      "forecast_bias: -3.3344099317416322\n",
      "training_time: 139.458092212677\n",
      "___\n",
      "=======\n",
      "Results for rnn\n",
      "window_size: 7\n",
      "rmse: 2.0624866541420057\n",
      "mae: 1.6207717054768613\n",
      "smape: 23.757225051808952\n",
      "r2: 0.9215524217645003\n",
      "forecast_bias: -0.03199400181628476\n",
      "training_time: 85.91135025024414\n",
      "___\n",
      "window_size: 14\n",
      "rmse: 2.0505931277034577\n",
      "mae: 1.57108947257584\n",
      "smape: 23.039187372535448\n",
      "r2: 0.9225057325000253\n",
      "forecast_bias: 0.0747754731344673\n",
      "training_time: 145.0789122581482\n",
      "___\n",
      "window_size: 30\n",
      "rmse: 2.069290049453345\n",
      "mae: 1.6021037984953008\n",
      "smape: 23.23448894711183\n",
      "r2: 0.9211086078276784\n",
      "forecast_bias: -0.27127702669563614\n",
      "training_time: 273.5228967666626\n",
      "___\n",
      "window_size: 60\n",
      "rmse: 2.0530974151790744\n",
      "mae: 1.599052043189251\n",
      "smape: 22.492060258330437\n",
      "r2: 0.9203990225435261\n",
      "forecast_bias: -0.1284325545545367\n",
      "training_time: 519.8827443122864\n",
      "___\n",
      "window_size: 180\n",
      "rmse: 2.263123268563629\n",
      "mae: 1.7404590818564414\n",
      "smape: 24.416102185438312\n",
      "r2: 0.9036690413734811\n",
      "forecast_bias: -0.5209357082488285\n",
      "training_time: 1448.0793051719666\n",
      "___\n",
      "window_size: 365\n",
      "rmse: 2.0805863724826628\n",
      "mae: 1.6253719103421158\n",
      "smape: 22.974865511023907\n",
      "r2: 0.9159991096179296\n",
      "forecast_bias: 0.09042472590105613\n",
      "training_time: 2891.388147354126\n",
      "___\n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_results in results.items():\n",
    "    print(f\"Results for {model_name}\")\n",
    "    for key, item in model_results.items():\n",
    "        if \"Error\" in key:\n",
    "            print(item)\n",
    "        else:\n",
    "            for metric_name, metric_value in item.items():\n",
    "                if metric_name != \"model_name\":\n",
    "                    print(f\"{metric_name}: {metric_value}\")\n",
    "        print(\"___\")\n",
    "    print(\"=======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f47b87-3eee-4e84-bd04-9c4e5d5da3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
